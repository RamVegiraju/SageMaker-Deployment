# Code Samples For [SageMaker Inference YouTube Series](https://www.youtube.com/watch?v=omFOOr4elnc&list=PLThJtS7RDkOeo9mpNjFVnIGDyiazAm9Uk)

## Table of Contents
You can watch in any order you feel is best/ideal for yourself, but I've structured it so that you can follow in this linear format for those of you that are new to SageMaker Inference.

1. [SageMaker Inference Options Overview](https://www.youtube.com/watch?v=pVVKqiMiArc&t=12s)
2. [Pre-Trained Single Model Deployment SageMaker Real-Time Inference](https://www.youtube.com/watch?v=omFOOr4elnc&t=924s)
3. [Debugging SageMaker Endpoints Using Docker](https://www.youtube.com/watch?v=UQHufr-DToE)
4. [Load Testing SageMaker Endpoints](https://www.youtube.com/watch?v=ZURoZZbiqj0&t=5s)
5. [AutoScaling SageMaker Endpoints](https://www.youtube.com/watch?v=I_KYnCvREzw&list=PLThJtS7RDkOeo9mpNjFVnIGDyiazAm9Uk&index=5)
6. [Multi-Model Hosting Options Available on SageMaker](https://www.youtube.com/watch?v=egQp4_oWWFM&list=PLThJtS7RDkOeo9mpNjFVnIGDyiazAm9Uk&index=6)
7. [Multi-Model Endpoints Hands-On](https://www.youtube.com/watch?v=hA7Zx9Wf--M&list=PLThJtS7RDkOeo9mpNjFVnIGDyiazAm9Uk&index=7)
8. [LLM Hosting Options on Amazon SageMaker](https://www.youtube.com/watch?v=ofh1Z4aW8Qk)
9. [Hosting LLMs with the Large Model Inference Container](https://www.youtube.com/watch?v=Q-Kz5Yi0QiQ&t=728s)
10. [SageMaker Inference Components: Deploying Multiple LLMs on One Endpoint](https://www.youtube.com/watch?v=RcUNEeUqpNQ&t=1024s)
