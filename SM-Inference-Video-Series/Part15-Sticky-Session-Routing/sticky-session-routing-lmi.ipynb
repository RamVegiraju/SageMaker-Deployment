{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b7782f-d355-4f65-9573-dd60bc4b76b4",
   "metadata": {},
   "source": [
    "# Sticky Session Routing SageMaker LMI Container\n",
    "Another feature of the LMI v16 container is support for sticky session routing which enables stateful GenAI applications. With Sticky Session Routing, requests from the same session are routed to the same instance. This allows for your application to reuse previously processed information to reduce latency and improve user experience.\n",
    "\n",
    "### Additional Resources/Credits\n",
    "- Initially Launched with the TorchServe Container: https://aws.amazon.com/blogs/machine-learning/build-ultra-low-latency-multimodal-generative-ai-applications-using-sticky-session-routing-in-amazon/\n",
    "- LMI v16 Official Docs/NB (most of the code is borrowed from here): https://github.com/deepjavalibrary/djl-demo/blob/master/aws/sagemaker/large-model-inference/sample-llm/stateful_inference_llama3_8b.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18e918-e36e-4428-9baa-da609af6a96d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246aa59-d989-4f82-8e42-50ef8bd4ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker --upgrade --quiet --no-warn-conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a8d767-20a2-4b90-9797-972a5457ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")  # client to intreract with SageMaker\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")  # client to intreract with SageMaker Endpoints\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "print(f\"sagemaker version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1dea0-584d-4128-8f28-ceca05fb7e59",
   "metadata": {},
   "source": [
    "## Deploy SM Qwen Endpoint using LMI v16 Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e198a-6551-4f39-93bc-01dc603e3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify hardware\n",
    "instance_type = \"ml.g5.4xlarge\"\n",
    "num_gpu = 1\n",
    "\n",
    "# specify container LMIv16\n",
    "CONTAINER_VERSION = \"0.34.0-lmi16.0.0-cu128\"\n",
    "inference_image = f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:{CONTAINER_VERSION}\"\n",
    "print(f\"Using image URI: {inference_image}\")\n",
    "\n",
    "#utilize the vLLM async handler: \n",
    "vllm_env = {\n",
    "    \"HF_MODEL_ID\": \"Qwen/Qwen3-1.7B\",\n",
    "    \"HF_TOKEN\": \"Enter HF Token here\",\n",
    "    \"SERVING_FAIL_FAST\": \"true\",\n",
    "    \"OPTION_ASYNC_MODE\": \"true\",\n",
    "    \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "    \"OPTION_TENSOR_PARALLEL_DEGREE\": json.dumps(num_gpu),\n",
    "    \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "    \"OPTION_TRUST_REMOTE_CODE\": \"true\",\n",
    "    \"OPTION_SESSIONS_EXPIRATION\": \"3600\" #session expiration, specifies time in seconds a session remains valid before it expires, defaults to 1200\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bbfb4-092a-4953-b04e-b0804cc9680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Model Creation\n",
    "model_name = \"lmi-sticky-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        \"Image\": inference_image,\n",
    "        \"Environment\": vllm_env,\n",
    "    },\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])\n",
    "\n",
    "#Step 2: EPC Creation\n",
    "epc_name = \"lmi-sticky-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialInstanceCount\": 2,\n",
    "            \"ModelDataDownloadTimeoutInSeconds\": 1800,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 1800,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])\n",
    "\n",
    "#Step 3: EP Creation\n",
    "endpoint_name = \"lmi-sticky-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=epc_name\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "#Monitor ep creation\n",
    "describe_endpoint_response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(60)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f8652-872e-4e3d-ad61-2d8e741b9808",
   "metadata": {},
   "source": [
    "## Start Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169db70-dc3f-4120-b3ff-059d1dac4e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"requestType\": \"NEW_SESSION\"\n",
    "}\n",
    "payload = json.dumps(payload)\n",
    "\n",
    "create_session_response = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=\"application/json\",\n",
    "    SessionId=\"NEW_SESSION\")\n",
    "\n",
    "session_id = create_session_response['ResponseMetadata']['HTTPHeaders']['x-amzn-sagemaker-new-session-id'].split(';')[0]\n",
    "print(f\"Created Session ID: {session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51043a90-963a-4e9f-8f7d-62ffb4cdd3a6",
   "metadata": {},
   "source": [
    "## Invoke EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c542afe-a41a-4f97-a39b-36473840db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_model = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps({\"inputs\": \"What is Amazon SageMaker?\"}),\n",
    "    ContentType=\"application/json\",\n",
    "    SessionId=session_id\n",
    ")\n",
    "result = json.loads(response_model['Body'].read().decode())['generated_text']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91b280-1b28-4b25-97d7-b9d0830afd94",
   "metadata": {},
   "source": [
    "## Close Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b400a-e93a-446e-a4ff-abf0a3d14728",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"requestType\": \"CLOSE\"\n",
    "}\n",
    "payload = json.dumps(payload)\n",
    "\n",
    "close_session_response = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=\"application/json\",\n",
    "    SessionId=session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1ed6d-54e5-450e-91b2-38e8bb7637bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_session_id = close_session_response['ResponseMetadata']['HTTPHeaders']['x-amzn-sagemaker-closed-session-id']\n",
    "\n",
    "print(f\"closed_session_id: {closed_session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad9e27-d94a-4627-b2ef-56865bd79548",
   "metadata": {},
   "source": [
    "## Can't Invoke Closed Session\n",
    "Here we see when we try invoke the session we closed we are unable to as it's been terminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db28468-7b9e-41a8-b71e-1be6becfd76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_model = smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps({\"inputs\": \"What is Amazon SageMaker?\"}),\n",
    "    ContentType=\"application/json\",\n",
    "    SessionId=session_id\n",
    ")\n",
    "result = json.loads(response_model['Body'].read().decode())['generated_text']\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
