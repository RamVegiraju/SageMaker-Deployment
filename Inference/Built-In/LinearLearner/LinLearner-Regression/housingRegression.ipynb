{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AWS SageMaker Linear Learner for Boston Housing Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>5.961</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>376.94</td>\n",
       "      <td>9.88</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10328</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453</td>\n",
       "      <td>5.927</td>\n",
       "      <td>47.2</td>\n",
       "      <td>6.9320</td>\n",
       "      <td>8.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.22</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.34940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.972</td>\n",
       "      <td>76.7</td>\n",
       "      <td>3.1025</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>396.24</td>\n",
       "      <td>9.97</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.73397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.597</td>\n",
       "      <td>94.9</td>\n",
       "      <td>1.5257</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>351.85</td>\n",
       "      <td>21.45</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04337</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>6.115</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6.8147</td>\n",
       "      <td>4.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>393.97</td>\n",
       "      <td>9.43</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "0  0.15876   0.0  10.81   0.0  0.413  5.961  17.5  5.2873  4.0  305.0   \n",
       "1  0.10328  25.0   5.13   0.0  0.453  5.927  47.2  6.9320  8.0  284.0   \n",
       "2  0.34940   0.0   9.90   0.0  0.544  5.972  76.7  3.1025  4.0  304.0   \n",
       "3  2.73397   0.0  19.58   0.0  0.871  5.597  94.9  1.5257  5.0  403.0   \n",
       "4  0.04337  21.0   5.64   0.0  0.439  6.115  63.0  6.8147  4.0  243.0   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     19.2  376.94   9.88  21.7  \n",
       "1     19.7  396.90   9.22  19.6  \n",
       "2     18.4  396.24   9.97  20.3  \n",
       "3     14.7  351.85  21.45  15.4  \n",
       "4     16.8  393.97   9.43  20.5  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Source: https://www.kaggle.com/c/boston-dataset/data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('boston_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404 entries, 0 to 403\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     404 non-null    float64\n",
      " 1   zn       404 non-null    float64\n",
      " 2   indus    404 non-null    float64\n",
      " 3   chas     404 non-null    float64\n",
      " 4   nox      404 non-null    float64\n",
      " 5   rm       404 non-null    float64\n",
      " 6   age      404 non-null    float64\n",
      " 7   dis      404 non-null    float64\n",
      " 8   rad      404 non-null    float64\n",
      " 9   tax      404 non-null    float64\n",
      " 10  ptratio  404 non-null    float64\n",
      " 11  black    404 non-null    float64\n",
      " 12  lstat    404 non-null    float64\n",
      " 13  medv     404 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 44.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our response variable is **medv**: median value of owner occupied homes in thousands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crim       0\n",
       "zn         0\n",
       "indus      0\n",
       "chas       0\n",
       "nox        0\n",
       "rm         0\n",
       "age        0\n",
       "dis        0\n",
       "rad        0\n",
       "tax        0\n",
       "ptratio    0\n",
       "black      0\n",
       "lstat      0\n",
       "medv       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.00000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.730912</td>\n",
       "      <td>10.509901</td>\n",
       "      <td>11.189901</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>6.30145</td>\n",
       "      <td>68.601733</td>\n",
       "      <td>3.799666</td>\n",
       "      <td>9.836634</td>\n",
       "      <td>411.688119</td>\n",
       "      <td>18.444554</td>\n",
       "      <td>355.068243</td>\n",
       "      <td>12.598936</td>\n",
       "      <td>22.312376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.943922</td>\n",
       "      <td>22.053733</td>\n",
       "      <td>6.814909</td>\n",
       "      <td>0.254290</td>\n",
       "      <td>0.117321</td>\n",
       "      <td>0.67583</td>\n",
       "      <td>28.066143</td>\n",
       "      <td>2.109916</td>\n",
       "      <td>8.834741</td>\n",
       "      <td>171.073553</td>\n",
       "      <td>2.150295</td>\n",
       "      <td>94.489572</td>\n",
       "      <td>6.925173</td>\n",
       "      <td>8.837019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>3.56100</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.169100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>5.90275</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>2.087875</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>17.375000</td>\n",
       "      <td>374.710000</td>\n",
       "      <td>7.135000</td>\n",
       "      <td>17.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.253715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.795000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.23050</td>\n",
       "      <td>76.600000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>391.065000</td>\n",
       "      <td>11.265000</td>\n",
       "      <td>21.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.053158</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>6.62925</td>\n",
       "      <td>94.150000</td>\n",
       "      <td>5.222125</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.007500</td>\n",
       "      <td>16.910000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.78000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>34.370000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox         rm  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.00000   \n",
       "mean     3.730912   10.509901   11.189901    0.069307    0.556710    6.30145   \n",
       "std      8.943922   22.053733    6.814909    0.254290    0.117321    0.67583   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.392000    3.56100   \n",
       "25%      0.082382    0.000000    5.190000    0.000000    0.453000    5.90275   \n",
       "50%      0.253715    0.000000    9.795000    0.000000    0.538000    6.23050   \n",
       "75%      4.053158   12.500000   18.100000    0.000000    0.631000    6.62925   \n",
       "max     88.976200   95.000000   27.740000    1.000000    0.871000    8.78000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio       black  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean    68.601733    3.799666    9.836634  411.688119   18.444554  355.068243   \n",
       "std     28.066143    2.109916    8.834741  171.073553    2.150295   94.489572   \n",
       "min      2.900000    1.169100    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.800000    2.087875    4.000000  281.000000   17.375000  374.710000   \n",
       "50%     76.600000    3.207450    5.000000  330.000000   19.000000  391.065000   \n",
       "75%     94.150000    5.222125   24.000000  666.000000   20.200000  396.007500   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            lstat        medv  \n",
       "count  404.000000  404.000000  \n",
       "mean    12.598936   22.312376  \n",
       "std      6.925173    8.837019  \n",
       "min      1.730000    5.000000  \n",
       "25%      7.135000   17.100000  \n",
       "50%     11.265000   21.400000  \n",
       "75%     16.910000   25.000000  \n",
       "max     34.370000   50.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally we would do more **EDA and data analysis**, but the purpose of this tutorial is to show how to fit your dataset with Linear Learner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['medv'], axis = 1)\n",
    "y = df['medv']\n",
    "\n",
    "#Need to do this to be able to convert to appropriate data format for Linear Learner algorithm later\n",
    "X = np.array(X).astype('float32')\n",
    "y = np.array(y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Linear Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::906815961619:role/service-role/AmazonSageMaker-ExecutionRole-20201221T212391\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "#Create a SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = \"linlearner-housingdata\"\n",
    "prefix = \"linear-learner\" #prefix is a sub-folder/key within the S3 bucket\n",
    "\n",
    "#Access SageMaker role created prior to session\n",
    "#Need to pass role to training job\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Need to convert dataset to RecordIO format for Linear Learner to understand\n",
    "import io \n",
    "import sagemaker.amazon.common as smac \n",
    "import os\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, X_train, y_train)\n",
    "buf.seek(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to upload **training data to S3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://linlearner-housingdata/linear-learner/train/linear-train-data\n"
     ]
    }
   ],
   "source": [
    "#Filename for training data we are uploading to S3 \n",
    "key = 'linear-train-data'\n",
    "\n",
    "#Upload training data to S3\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload test data to S3 as well to evaluate algorithm later, repeat same steps with X_test and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://linlearner-housingdata/linear-learner/test/linear-test-data\n"
     ]
    }
   ],
   "source": [
    "buf = io.BytesIO() # create an in-memory byte array (buf is a buffer I will be writing to)\n",
    "smac.write_numpy_to_dense_tensor(buf, X_test, y_test)\n",
    "buf.seek(0)\n",
    "\n",
    "#Sub-folder for test data\n",
    "key = 'linear-test-data'\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test', key)).upload_fileobj(buf)\n",
    "s3_test_data = 's3://{}/{}/test/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to store the **model training artifacts** in the S3 bucket as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training artifacts will be uploaded to: s3://linlearner-housingdata/linear-learner/output\n"
     ]
    }
   ],
   "source": [
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to access the training container of Linear Learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import image_uris\n",
    "container = image_uris.retrieve('linear-learner', boto3.Session().region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-22 03:11:32 Starting - Starting the training job...\n",
      "2020-12-22 03:11:56 Starting - Launching requested ML instancesProfilerReport-1608606692: InProgress\n",
      ".........\n",
      "2020-12-22 03:13:17 Starting - Preparing the instances for training.........\n",
      "2020-12-22 03:14:58 Downloading - Downloading input data\n",
      "2020-12-22 03:14:58 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:13 INFO 139881125381952] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'auto', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:13 INFO 139881125381952] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'loss': u'absolute_loss', u'mini_batch_size': u'20', u'predictor_type': u'regressor', u'epochs': u'5', u'feature_dim': u'13', u'num_models': u'10'}\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:13 INFO 139881125381952] Final configuration: {u'loss_insensitivity': u'0.01', u'epochs': u'5', u'feature_dim': u'13', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'10', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'20', u'huber_delta': u'1.0', u'num_classes': u'1', u'predictor_type': u'regressor', u'beta_1': u'auto', u'loss': u'absolute_loss', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:13 WARNING 139881125381952] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:13 INFO 139881125381952] Using default worker.\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2020-12-22 03:15:14.032] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 14, \"num_examples\": 1, \"num_bytes\": 1920}\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Create Store: local\u001b[0m\n",
      "\u001b[34m[2020-12-22 03:15:14.150] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 117, \"num_examples\": 15, \"num_bytes\": 27072}\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f383d3ca610>\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Scaling model computed with parameters:\n",
      " {'stdev_weight': \u001b[0m\n",
      "\u001b[34m[7.95052385e+00 2.21484089e+01 6.54133129e+00 2.57539362e-01\n",
      " 1.13825046e-01 6.52625442e-01 2.71723213e+01 2.09929729e+00\n",
      " 8.72536755e+00 1.67606949e+02 2.09890795e+00 9.66914215e+01\n",
      " 6.84927130e+00]\u001b[0m\n",
      "\u001b[34m<NDArray 13 @cpu(0)>, 'stdev_label': \u001b[0m\n",
      "\u001b[34m[8.524221]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_label': \u001b[0m\n",
      "\u001b[34m[22.388931]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[3.4077280e+00 1.0610715e+01 1.0737536e+01 7.1428582e-02 5.5258965e-01\n",
      " 6.3294215e+00 6.8720718e+01 3.8153138e+00 9.7607164e+00 4.0618570e+02\n",
      " 1.8471069e+01 3.5530704e+02 1.2620607e+01]\u001b[0m\n",
      "\u001b[34m<NDArray 13 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] nvidia-smi took: 0.0251929759979 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}, \"Total Records Seen\": {\"count\": 1, \"max\": 302, \"sum\": 302.0, \"min\": 302}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 282, \"sum\": 282.0, \"min\": 282}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1608606914.208091, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1608606914.208044}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-12-22 03:15:14.325] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 117, \"num_examples\": 15, \"num_bytes\": 27072}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.5766383988516671, \"sum\": 0.5766383988516671, \"min\": 0.5766383988516671}}, \"EndTime\": 1608606914.32585, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1608606914.325795}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.5534902964319501, \"sum\": 0.5534902964319501, \"min\": 0.5534902964319501}}, \"EndTime\": 1608606914.325934, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1608606914.325921}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.630046626499721, \"sum\": 0.630046626499721, \"min\": 0.630046626499721}}, \"EndTime\": 1608606914.325976, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1608606914.325962}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.5942680290767125, \"sum\": 0.5942680290767125, \"min\": 0.5942680290767125}}, \"EndTime\": 1608606914.326031, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1608606914.326016}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.6888783931732178, \"sum\": 0.6888783931732178, \"min\": 0.6888783931732178}}, \"EndTime\": 1608606914.326083, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1608606914.326068}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.7154712268284389, \"sum\": 0.7154712268284389, \"min\": 0.7154712268284389}}, \"EndTime\": 1608606914.326133, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1608606914.326118}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.5571050184113638, \"sum\": 0.5571050184113638, \"min\": 0.5571050184113638}}, \"EndTime\": 1608606914.326189, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1608606914.326174}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.6294248155185155, \"sum\": 0.6294248155185155, \"min\": 0.6294248155185155}}, \"EndTime\": 1608606914.326247, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1608606914.326231}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.5588052817753383, \"sum\": 0.5588052817753383, \"min\": 0.5588052817753383}}, \"EndTime\": 1608606914.326305, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1608606914.326289}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.6667887006487165, \"sum\": 0.6667887006487165, \"min\": 0.6667887006487165}}, \"EndTime\": 1608606914.326362, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1608606914.326345}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #quality_metric: host=algo-1, epoch=0, train absolute_loss_objective <loss>=0.576638398852\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=absolute_loss_objective, value=0.553490296432\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Saved checkpoint to \"/tmp/tmp7NjT7p/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 282, \"sum\": 282.0, \"min\": 282}, \"Total Batches Seen\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Total Records Seen\": {\"count\": 1, \"max\": 584, \"sum\": 584.0, \"min\": 584}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 282, \"sum\": 282.0, \"min\": 282}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1608606914.338428, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1608606914.208308}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #throughput_metric: host=algo-1, train throughput=2165.66615094 records/second\u001b[0m\n",
      "\u001b[34m[2020-12-22 03:15:14.437] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 98, \"num_examples\": 15, \"num_bytes\": 27072}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.45585191760744365, \"sum\": 0.45585191760744365, \"min\": 0.45585191760744365}}, \"EndTime\": 1608606914.437458, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1608606914.437403}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.45685058661869593, \"sum\": 0.45685058661869593, \"min\": 0.45685058661869593}}, \"EndTime\": 1608606914.437543, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1608606914.437528}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4830036742346627, \"sum\": 0.4830036742346627, \"min\": 0.4830036742346627}}, \"EndTime\": 1608606914.437595, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1608606914.437582}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4775585583278111, \"sum\": 0.4775585583278111, \"min\": 0.4775585583278111}}, \"EndTime\": 1608606914.437639, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1608606914.437629}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.5117425697190421, \"sum\": 0.5117425697190421, \"min\": 0.5117425697190421}}, \"EndTime\": 1608606914.43768, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1608606914.437669}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.519575491973332, \"sum\": 0.519575491973332, \"min\": 0.519575491973332}}, \"EndTime\": 1608606914.43772, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1608606914.43771}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.44242932966777254, \"sum\": 0.44242932966777254, \"min\": 0.44242932966777254}}, \"EndTime\": 1608606914.43776, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1608606914.43775}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.3951383573668344, \"sum\": 0.3951383573668344, \"min\": 0.3951383573668344}}, \"EndTime\": 1608606914.437799, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1608606914.437789}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4586592299597604, \"sum\": 0.4586592299597604, \"min\": 0.4586592299597604}}, \"EndTime\": 1608606914.437837, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1608606914.437827}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.520393557207925, \"sum\": 0.520393557207925, \"min\": 0.520393557207925}}, \"EndTime\": 1608606914.437875, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1608606914.437865}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #quality_metric: host=algo-1, epoch=1, train absolute_loss_objective <loss>=0.455851917607\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=absolute_loss_objective, value=0.395138357367\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Saved checkpoint to \"/tmp/tmpVib8gn/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 282, \"sum\": 282.0, \"min\": 282}, \"Total Batches Seen\": {\"count\": 1, \"max\": 46, \"sum\": 46.0, \"min\": 46}, \"Total Records Seen\": {\"count\": 1, \"max\": 866, \"sum\": 866.0, \"min\": 866}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 282, \"sum\": 282.0, \"min\": 282}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1608606914.445105, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1608606914.338695}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #throughput_metric: host=algo-1, train throughput=2647.31468475 records/second\u001b[0m\n",
      "\u001b[34m[2020-12-22 03:15:14.538] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 92, \"num_examples\": 15, \"num_bytes\": 27072}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4124225105558123, \"sum\": 0.4124225105558123, \"min\": 0.4124225105558123}}, \"EndTime\": 1608606914.53842, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1608606914.538376}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.41033876282828197, \"sum\": 0.41033876282828197, \"min\": 0.41033876282828197}}, \"EndTime\": 1608606914.538485, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1608606914.538471}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4247813940048218, \"sum\": 0.4247813940048218, \"min\": 0.4247813940048218}}, \"EndTime\": 1608606914.538534, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1608606914.538523}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4302243454115731, \"sum\": 0.4302243454115731, \"min\": 0.4302243454115731}}, \"EndTime\": 1608606914.538575, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1608606914.538565}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.38722997222627914, \"sum\": 0.38722997222627914, \"min\": 0.38722997222627914}}, \"EndTime\": 1608606914.538614, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1608606914.538604}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4076195699828012, \"sum\": 0.4076195699828012, \"min\": 0.4076195699828012}}, \"EndTime\": 1608606914.538657, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1608606914.538647}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.39045915263039727, \"sum\": 0.39045915263039727, \"min\": 0.39045915263039727}}, \"EndTime\": 1608606914.538696, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1608606914.538686}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.39514956474304197, \"sum\": 0.39514956474304197, \"min\": 0.39514956474304197}}, \"EndTime\": 1608606914.538734, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1608606914.538724}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4057266269411359, \"sum\": 0.4057266269411359, \"min\": 0.4057266269411359}}, \"EndTime\": 1608606914.538772, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1608606914.538762}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4673288702964783, \"sum\": 0.4673288702964783, \"min\": 0.4673288702964783}}, \"EndTime\": 1608606914.538818, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1608606914.538807}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #quality_metric: host=algo-1, epoch=2, train absolute_loss_objective <loss>=0.412422510556\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=absolute_loss_objective, value=0.387229972226\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Saved checkpoint to \"/tmp/tmp9NAl9o/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 282, \"sum\": 282.0, \"min\": 282}, \"Total Batches Seen\": {\"count\": 1, \"max\": 61, \"sum\": 61.0, \"min\": 61}, \"Total Records Seen\": {\"count\": 1, \"max\": 1148, \"sum\": 1148.0, \"min\": 1148}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 282, \"sum\": 282.0, \"min\": 282}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1608606914.545152, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1608606914.445355}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #throughput_metric: host=algo-1, train throughput=2822.53969784 records/second\u001b[0m\n",
      "\u001b[34m[2020-12-22 03:15:14.682] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 136, \"num_examples\": 15, \"num_bytes\": 27072}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.37667778730392454, \"sum\": 0.37667778730392454, \"min\": 0.37667778730392454}}, \"EndTime\": 1608606914.682158, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1608606914.682096}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.37437179940087456, \"sum\": 0.37437179940087456, \"min\": 0.37437179940087456}}, \"EndTime\": 1608606914.682251, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1608606914.682231}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.37981880222048076, \"sum\": 0.37981880222048076, \"min\": 0.37981880222048076}}, \"EndTime\": 1608606914.682518, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1608606914.682495}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.388466705594744, \"sum\": 0.388466705594744, \"min\": 0.388466705594744}}, \"EndTime\": 1608606914.682652, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1608606914.68257}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.37492902449199134, \"sum\": 0.37492902449199134, \"min\": 0.37492902449199134}}, \"EndTime\": 1608606914.682731, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1608606914.682709}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.43157332795006886, \"sum\": 0.43157332795006886, \"min\": 0.43157332795006886}}, \"EndTime\": 1608606914.682803, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1608606914.68278}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.3864194461277553, \"sum\": 0.3864194461277553, \"min\": 0.3864194461277553}}, \"EndTime\": 1608606914.682987, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1608606914.682966}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.36533290488379344, \"sum\": 0.36533290488379344, \"min\": 0.36533290488379344}}, \"EndTime\": 1608606914.683051, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1608606914.683032}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.3715916974203927, \"sum\": 0.3715916974203927, \"min\": 0.3715916974203927}}, \"EndTime\": 1608606914.683237, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1608606914.683213}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4143045221056257, \"sum\": 0.4143045221056257, \"min\": 0.4143045221056257}}, \"EndTime\": 1608606914.683308, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1608606914.683289}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #quality_metric: host=algo-1, epoch=3, train absolute_loss_objective <loss>=0.376677787304\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=absolute_loss_objective, value=0.365332904884\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Saved checkpoint to \"/tmp/tmp7vtzIO/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 282, \"sum\": 282.0, \"min\": 282}, \"Total Batches Seen\": {\"count\": 1, \"max\": 76, \"sum\": 76.0, \"min\": 76}, \"Total Records Seen\": {\"count\": 1, \"max\": 1430, \"sum\": 1430.0, \"min\": 1430}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 282, \"sum\": 282.0, \"min\": 282}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1608606914.690292, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1608606914.545403}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #throughput_metric: host=algo-1, train throughput=1944.81505086 records/second\u001b[0m\n",
      "\u001b[34m[2020-12-22 03:15:14.807] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 116, \"num_examples\": 15, \"num_bytes\": 27072}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.3534815515790667, \"sum\": 0.3534815515790667, \"min\": 0.3534815515790667}}, \"EndTime\": 1608606914.807699, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1608606914.807635}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.35015544039862495, \"sum\": 0.35015544039862495, \"min\": 0.35015544039862495}}, \"EndTime\": 1608606914.807814, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1608606914.807794}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.3550205775669643, \"sum\": 0.3550205775669643, \"min\": 0.3550205775669643}}, \"EndTime\": 1608606914.807963, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1608606914.80794}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.35944417204175677, \"sum\": 0.35944417204175677, \"min\": 0.35944417204175677}}, \"EndTime\": 1608606914.808031, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1608606914.808012}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4016809037753514, \"sum\": 0.4016809037753514, \"min\": 0.4016809037753514}}, \"EndTime\": 1608606914.808097, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1608606914.808079}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4334160923957825, \"sum\": 0.4334160923957825, \"min\": 0.4334160923957825}}, \"EndTime\": 1608606914.808161, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1608606914.808143}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.392886871950967, \"sum\": 0.392886871950967, \"min\": 0.392886871950967}}, \"EndTime\": 1608606914.808224, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1608606914.808206}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.4160040923527309, \"sum\": 0.4160040923527309, \"min\": 0.4160040923527309}}, \"EndTime\": 1608606914.808286, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1608606914.808269}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.34818488359451294, \"sum\": 0.34818488359451294, \"min\": 0.34818488359451294}}, \"EndTime\": 1608606914.808401, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1608606914.808381}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_absolute_loss_objective\": {\"count\": 1, \"max\": 0.3780242494174412, \"sum\": 0.3780242494174412, \"min\": 0.3780242494174412}}, \"EndTime\": 1608606914.808468, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1608606914.808449}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #quality_metric: host=algo-1, epoch=4, train absolute_loss_objective <loss>=0.353481551579\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=absolute_loss_objective, value=0.348184883595\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Saved checkpoint to \"/tmp/tmpTeQLY6/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 282, \"sum\": 282.0, \"min\": 282}, \"Total Batches Seen\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Total Records Seen\": {\"count\": 1, \"max\": 1712, \"sum\": 1712.0, \"min\": 1712}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 282, \"sum\": 282.0, \"min\": 282}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1608606914.815424, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1608606914.690539}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #throughput_metric: host=algo-1, train throughput=2255.69452989 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 WARNING 139881125381952] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 WARNING 139881125381952] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2020-12-22 03:15:14.816] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 0, \"num_examples\": 1, \"num_bytes\": 1920}\u001b[0m\n",
      "\u001b[34m[2020-12-22 03:15:14.841] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 21, \"num_examples\": 15, \"num_bytes\": 27072}\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #train_score (algo-1) : ('absolute_loss_objective', 2.8953908555051115)\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #train_score (algo-1) : ('mse', 18.883607309760777)\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #train_score (algo-1) : ('absolute_loss', 2.8953908555051115)\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #quality_metric: host=algo-1, train absolute_loss_objective <loss>=2.89539085551\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #quality_metric: host=algo-1, train mse <loss>=18.8836073098\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] #quality_metric: host=algo-1, train absolute_loss <loss>=2.89539085551\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Best model found for hyperparameters: {\"lr_scheduler_step\": 10, \"wd\": 0.01, \"optimizer\": \"adam\", \"lr_scheduler_factor\": 0.99, \"l1\": 0.0, \"learning_rate\": 0.005, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Saved checkpoint to \"/tmp/tmpdC7ZxO/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/22/2020 03:15:14 INFO 139881125381952] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1063.5550022125244, \"sum\": 1063.5550022125244, \"min\": 1063.5550022125244}, \"finalize.time\": {\"count\": 1, \"max\": 26.3669490814209, \"sum\": 26.3669490814209, \"min\": 26.3669490814209}, \"initialize.time\": {\"count\": 1, \"max\": 189.76712226867676, \"sum\": 189.76712226867676, \"min\": 189.76712226867676}, \"check_early_stopping.time\": {\"count\": 5, \"max\": 1.1360645294189453, \"sum\": 5.281209945678711, \"min\": 0.8800029754638672}, \"setuptime\": {\"count\": 1, \"max\": 28.100013732910156, \"sum\": 28.100013732910156, \"min\": 28.100013732910156}, \"update.time\": {\"count\": 5, \"max\": 142.42005348205566, \"sum\": 590.4510021209717, \"min\": 97.56898880004883}, \"epochs\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1608606914.845499, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1608606914.016642}\n",
      "\u001b[0m\n",
      "\n",
      "2020-12-22 03:15:28 Uploading - Uploading generated training model\n",
      "2020-12-22 03:15:28 Completed - Training job completed\n",
      "Training seconds: 50\n",
      "Billable seconds: 50\n"
     ]
    }
   ],
   "source": [
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       instance_count = 1, \n",
    "                                       instance_type = 'ml.c4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session)\n",
    "\n",
    "#Different hyperparameters we can tune with Linear Learner in the link below\n",
    "#https://docs.aws.amazon.com/sagemaker/latest/dg/ll_hyperparameters.html\n",
    "#We have 13 input features in X_train, our model problem is regression\n",
    "linear.set_hyperparameters(feature_dim = 13,\n",
    "                           predictor_type = 'regressor',\n",
    "                           mini_batch_size = 20,\n",
    "                           epochs = 5,\n",
    "                           num_models = 10,\n",
    "                           loss = 'absolute_loss')\n",
    "\n",
    "#Pass in S3 training_data path variable we declared earlier\n",
    "linear.fit({'train': s3_train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Model (Endpoint Creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "linear_regressor = linear.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "#need to make sure data is in correct format for deployed model\n",
    "linear_regressor.serializer = csv_serializer\n",
    "linear_regressor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The json_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 23.74055290222168},\n",
       "  {'score': 29.536836624145508},\n",
       "  {'score': 15.630285263061523},\n",
       "  {'score': 28.122840881347656},\n",
       "  {'score': 23.221267700195312},\n",
       "  {'score': 16.42348861694336},\n",
       "  {'score': 32.72686767578125},\n",
       "  {'score': 26.281394958496094},\n",
       "  {'score': 17.627180099487305},\n",
       "  {'score': 22.398662567138672},\n",
       "  {'score': 15.902243614196777},\n",
       "  {'score': 18.05726432800293},\n",
       "  {'score': 26.32111167907715},\n",
       "  {'score': 18.564197540283203},\n",
       "  {'score': 15.920336723327637},\n",
       "  {'score': 24.424623489379883},\n",
       "  {'score': 21.297504425048828},\n",
       "  {'score': 16.516252517700195},\n",
       "  {'score': 8.171432495117188},\n",
       "  {'score': 19.457088470458984},\n",
       "  {'score': 32.516815185546875},\n",
       "  {'score': 15.452421188354492},\n",
       "  {'score': 20.18819808959961},\n",
       "  {'score': 24.0698184967041},\n",
       "  {'score': 18.686058044433594},\n",
       "  {'score': 21.536666870117188},\n",
       "  {'score': 28.89977264404297},\n",
       "  {'score': 16.968124389648438},\n",
       "  {'score': 21.178634643554688},\n",
       "  {'score': 17.187355041503906},\n",
       "  {'score': 19.297286987304688},\n",
       "  {'score': 23.677715301513672},\n",
       "  {'score': 23.15020179748535},\n",
       "  {'score': 22.050458908081055},\n",
       "  {'score': 21.656156539916992},\n",
       "  {'score': 21.339035034179688},\n",
       "  {'score': 17.358673095703125},\n",
       "  {'score': 25.018962860107422},\n",
       "  {'score': 19.34954261779785},\n",
       "  {'score': 11.395220756530762},\n",
       "  {'score': 30.252605438232422},\n",
       "  {'score': 22.882015228271484},\n",
       "  {'score': 14.603286743164062},\n",
       "  {'score': 15.554624557495117},\n",
       "  {'score': 33.43067932128906},\n",
       "  {'score': 30.803359985351562},\n",
       "  {'score': 38.86907196044922},\n",
       "  {'score': 0.9448013305664062},\n",
       "  {'score': 11.31666374206543},\n",
       "  {'score': 38.32395935058594},\n",
       "  {'score': 17.33897590637207},\n",
       "  {'score': 25.65936279296875},\n",
       "  {'score': 24.89542007446289},\n",
       "  {'score': 24.757545471191406},\n",
       "  {'score': 15.865670204162598},\n",
       "  {'score': 16.223590850830078},\n",
       "  {'score': 23.05670928955078},\n",
       "  {'score': 22.84830093383789},\n",
       "  {'score': 15.549153327941895},\n",
       "  {'score': 23.739269256591797},\n",
       "  {'score': 5.919795989990234},\n",
       "  {'score': 13.631060600280762},\n",
       "  {'score': 15.286637306213379},\n",
       "  {'score': 25.00298500061035},\n",
       "  {'score': 7.5670270919799805},\n",
       "  {'score': 17.32854652404785},\n",
       "  {'score': 13.999337196350098},\n",
       "  {'score': 11.847692489624023},\n",
       "  {'score': 15.795960426330566},\n",
       "  {'score': 21.710302352905273},\n",
       "  {'score': 25.073387145996094},\n",
       "  {'score': 31.17344856262207},\n",
       "  {'score': 20.49286460876465},\n",
       "  {'score': 27.816728591918945},\n",
       "  {'score': 30.969552993774414},\n",
       "  {'score': 21.410436630249023},\n",
       "  {'score': 18.260623931884766},\n",
       "  {'score': 19.0748291015625},\n",
       "  {'score': 24.9521484375},\n",
       "  {'score': 18.437541961669922},\n",
       "  {'score': 15.579744338989258},\n",
       "  {'score': 25.438671112060547},\n",
       "  {'score': 23.072429656982422},\n",
       "  {'score': 15.012686729431152},\n",
       "  {'score': 28.162574768066406},\n",
       "  {'score': 34.252906799316406},\n",
       "  {'score': 8.363897323608398},\n",
       "  {'score': 24.260780334472656},\n",
       "  {'score': 5.671425819396973},\n",
       "  {'score': 24.9224853515625},\n",
       "  {'score': 13.740056991577148},\n",
       "  {'score': 23.449243545532227},\n",
       "  {'score': 28.15496826171875},\n",
       "  {'score': 16.890806198120117},\n",
       "  {'score': 21.455167770385742},\n",
       "  {'score': 6.044842720031738},\n",
       "  {'score': 9.556000709533691},\n",
       "  {'score': 22.220691680908203},\n",
       "  {'score': 27.86589241027832},\n",
       "  {'score': 24.424335479736328},\n",
       "  {'score': 32.16728591918945},\n",
       "  {'score': 25.459720611572266},\n",
       "  {'score': 12.961116790771484},\n",
       "  {'score': 12.301270484924316},\n",
       "  {'score': 26.582202911376953},\n",
       "  {'score': 27.953330993652344},\n",
       "  {'score': 28.339540481567383},\n",
       "  {'score': 8.448003768920898},\n",
       "  {'score': 23.180984497070312},\n",
       "  {'score': 15.351500511169434},\n",
       "  {'score': 21.548187255859375},\n",
       "  {'score': 32.005191802978516},\n",
       "  {'score': 22.359729766845703},\n",
       "  {'score': 19.161649703979492},\n",
       "  {'score': 27.028947830200195},\n",
       "  {'score': 20.316068649291992},\n",
       "  {'score': 14.788239479064941},\n",
       "  {'score': 18.69898796081543},\n",
       "  {'score': 26.9443359375},\n",
       "  {'score': 17.35906219482422},\n",
       "  {'score': 22.180469512939453},\n",
       "  {'score': 28.885351181030273}]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = linear_regressor.predict(X_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate the JSON to get a **predictions array** for us to compare to the actual y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.7405529 , 29.53683662, 15.63028526, 28.12284088, 23.2212677 ,\n",
       "       16.42348862, 32.72686768, 26.28139496, 17.6271801 , 22.39866257,\n",
       "       15.90224361, 18.05726433, 26.32111168, 18.56419754, 15.92033672,\n",
       "       24.42462349, 21.29750443, 16.51625252,  8.1714325 , 19.45708847,\n",
       "       32.51681519, 15.45242119, 20.18819809, 24.0698185 , 18.68605804,\n",
       "       21.53666687, 28.89977264, 16.96812439, 21.17863464, 17.18735504,\n",
       "       19.29728699, 23.6777153 , 23.1502018 , 22.05045891, 21.65615654,\n",
       "       21.33903503, 17.3586731 , 25.01896286, 19.34954262, 11.39522076,\n",
       "       30.25260544, 22.88201523, 14.60328674, 15.55462456, 33.43067932,\n",
       "       30.80335999, 38.86907196,  0.94480133, 11.31666374, 38.32395935,\n",
       "       17.33897591, 25.65936279, 24.89542007, 24.75754547, 15.8656702 ,\n",
       "       16.22359085, 23.05670929, 22.84830093, 15.54915333, 23.73926926,\n",
       "        5.91979599, 13.6310606 , 15.28663731, 25.002985  ,  7.56702709,\n",
       "       17.32854652, 13.9993372 , 11.84769249, 15.79596043, 21.71030235,\n",
       "       25.07338715, 31.17344856, 20.49286461, 27.81672859, 30.96955299,\n",
       "       21.41043663, 18.26062393, 19.0748291 , 24.95214844, 18.43754196,\n",
       "       15.57974434, 25.43867111, 23.07242966, 15.01268673, 28.16257477,\n",
       "       34.2529068 ,  8.36389732, 24.26078033,  5.67142582, 24.92248535,\n",
       "       13.74005699, 23.44924355, 28.15496826, 16.8908062 , 21.45516777,\n",
       "        6.04484272,  9.55600071, 22.22069168, 27.86589241, 24.42433548,\n",
       "       32.16728592, 25.45972061, 12.96111679, 12.30127048, 26.58220291,\n",
       "       27.95333099, 28.33954048,  8.44800377, 23.1809845 , 15.35150051,\n",
       "       21.54818726, 32.0051918 , 22.35972977, 19.1616497 , 27.02894783,\n",
       "       20.31606865, 14.78823948, 18.69898796, 26.94433594, 17.35906219,\n",
       "       22.18046951, 28.88535118])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array([res['score'] for res in result['predictions']])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first **visualize** how accurate our predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f101e2bdef0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f101e335f60>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot((y_test - predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate using **Root Mean Squared Error (RMSE)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.142996482475555"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "np.sqrt(metrics.mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
