{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa0b88c-ac60-4068-851b-862290e1bbe6",
   "metadata": {},
   "source": [
    "## BART Model Hosting With DJL Serving on Amazon SageMaker Real-Time Inference\n",
    "\n",
    "Setting: conda_amazonei_pytorch_latest_p37 Kernel & ml.c5.9xlarge Classic Notebook Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b6242-71ec-41c7-a1f9-8cfb8fb8e2b3",
   "metadata": {},
   "source": [
    "### Local Sample Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8338115c-3672-49b7-aa8d-a3dc7364b298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "model = AutoModel.from_pretrained(\"facebook/bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee155f-71a4-41e8-b94d-26180fcf41f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026bd79-265a-4ab9-873d-7dcd4a13aa20",
   "metadata": {},
   "source": [
    "### DJL Specific Artifacts\n",
    "\n",
    "For DJL Serving there are three artifacts we need to encapsulate in our model tarball\n",
    "\n",
    "- model.py: Your pre/post processing logic as well as model inference, you can add any customization in this script.\n",
    "- requirements.txt: Any other libraries or packages you utilize in your model.py\n",
    "- serving.properties: We define the engine and different configurations for DJL Serving, these are the environment variables that your model.py script can parse as well (captured in 'properties' object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31390cbe-717c-4a9d-9f12-6bc09d036c5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "from djl_python import Input\n",
    "from djl_python import Output\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BartModel(object):\n",
    "    \"\"\"\n",
    "    Deploying Bart with DJL Serving\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, properties: dict):\n",
    "        \"\"\"\n",
    "        Initialize model.\n",
    "        \"\"\"\n",
    "        print(os.listdir())\n",
    "        logging.info(\"-----------------\")\n",
    "        logging.info(properties)\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "        model = AutoModel.from_pretrained(\"facebook/bart-large\")\n",
    "        \n",
    "        self.model_name = properties.get(\"model_id\")\n",
    "        self.task = properties.get(\"task\")\n",
    "        logging.info(\"-----------------\")\n",
    "        logging.info(self.model_name)\n",
    "        logging.info(\"-----------------\")\n",
    "        logging.info(self.task)\n",
    "        self.model = AutoModel.from_pretrained(self.model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.initialized = True\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        \"\"\"\n",
    "        Custom service entry point function.\n",
    "\n",
    "        :param inputs: the Input object holds the text for the BART model to infer upon\n",
    "        :return: the Output object to be send back\n",
    "        \"\"\"\n",
    "\n",
    "        #sample input: \"This is the sample text that I am passing in\"\n",
    "        \n",
    "        try:\n",
    "            data = inputs.get_as_string()\n",
    "            logging.info(\"-----------------\")\n",
    "            logging.info(data)\n",
    "            logging.info(type(data))\n",
    "            logging.info(\"-----------------\")\n",
    "            inputs = self.tokenizer(data, return_tensors=\"pt\")\n",
    "            preds = self.model(**inputs)\n",
    "            logging.info(\"-----------------\")\n",
    "            logging.info(type(preds))\n",
    "            logging.info(\"-----------------\")\n",
    "            res = preds.last_hidden_state.detach().cpu().numpy().tolist() #convert to JSON Serializable object\n",
    "            outputs = Output()\n",
    "            outputs.add_as_json(res)\n",
    "        except Exception as e:\n",
    "            logging.exception(\"inference failed\")\n",
    "            # error handling\n",
    "            outputs = Output().error(str(e))\n",
    "        \n",
    "        print(outputs)\n",
    "        print(type(outputs))\n",
    "        print(\"Returning inference---------\")\n",
    "        return outputs\n",
    "\n",
    "\n",
    "_service = BartModel()\n",
    "\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    \"\"\"\n",
    "    Default handler function\n",
    "    \"\"\"\n",
    "    if not _service.initialized:\n",
    "        # stateful model\n",
    "        _service.initialize(inputs.get_properties())\n",
    "    \n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "\n",
    "    return _service.inference(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54920055-c121-40d9-b7a7-fa3abc46737d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de48fff4-33f9-4862-8ddf-f1c2477d47d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.model_id=facebook/bart-large\n",
    "option.task=feature-extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c95d6b-68fb-4f92-9de8-ae6483438295",
   "metadata": {},
   "source": [
    "### SageMaker Hosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8806ce0f-fb7c-4ba4-a4dc-d9ad0727eefe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "from sagemaker import image_uris\n",
    "import subprocess\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "\n",
    "instance_type = \"ml.g5.12xlarge\"\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "session = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = session._region_name\n",
    "bucket = session.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "img_uri = image_uris.retrieve(framework=\"djl-deepspeed\", region=region, version=\"0.21.0\")\n",
    "img_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a145db-a3e9-41aa-8726-f28175b92b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Build tar file with model data + inference code\n",
    "bashCommand = \"tar -cvpzf model.tar.gz model.py requirements.txt serving.properties\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ba857-a359-4eda-9a3c-cf43a5dea735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Upload tar.gz to bucket\n",
    "model_artifacts = f\"s3://{bucket}/model.tar.gz\"\n",
    "response = s3.meta.client.upload_file('model.tar.gz', bucket, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f448a-da1d-4a6f-b765-db03a7a567a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f11590-b74e-49ca-8ea5-b4b48af919e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"djl-bart\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name: \" + model_name)\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\"Image\": img_uri, \"ModelDataUrl\": model_artifacts},\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde132f7-3523-43eb-812e-2e3645529b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_config_name = \"djl-bart\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "production_variants = [\n",
    "    {\n",
    "        \"VariantName\": \"AllTraffic\",\n",
    "        \"ModelName\": model_name,\n",
    "        \"InitialInstanceCount\": 1,\n",
    "        \"InstanceType\": instance_type,\n",
    "        \"ModelDataDownloadTimeoutInSeconds\": 1800,\n",
    "        \"ContainerStartupHealthCheckTimeoutInSeconds\": 3600,\n",
    "    }\n",
    "]\n",
    "\n",
    "endpoint_config = {\n",
    "    \"EndpointConfigName\": endpoint_config_name,\n",
    "    \"ProductionVariants\": production_variants,\n",
    "}\n",
    "\n",
    "endpoint_config_response = client.create_endpoint_config(**endpoint_config)\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d2a70a-c764-48c7-8880-5cd66aeccfa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"djl-bart\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea383b77-bec9-45fc-856c-33efc36e9ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b5276-b6db-479c-af6a-fde1fbc661ac",
   "metadata": {},
   "source": [
    "### Sample Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ceb7a-2aac-4951-a6b7-a2d14c4c8289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"text/plain\",\n",
    "    Body=\"I think my dog is really cute!\")\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
