{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3b863b-5ae8-4683-a9c8-c3c172e1fc69",
   "metadata": {},
   "source": [
    "## BERT Custom Inference Script SageMaker Deployment\n",
    "\n",
    "Follow this repository from HuggingFace as a base: https://github.com/huggingface/notebooks/blob/main/sagemaker/17_custom_inference_script/sagemaker-notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33444e65-c628-4774-be57-ebebd378a988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sagemaker>=2.127.0 transformers==4.12.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba68c5a-726b-40ce-bfbb-07c7791a9829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b0d89d-1c4d-464b-b70a-15404c641b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e96ec-ef2a-4301-935b-5a297147ce16",
   "metadata": {},
   "source": [
    "### Local Inference Test\n",
    "\n",
    "This will make it easier for you to debug your inference script that you pass to SageMaker. You can understand input and output functionality beforehand essentially in terms of data format and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2525c63-fdd0-4e94-ae19-a58b2bb1bc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samp = \"This is a test string that I am trying out with the BERT model.\"\n",
    "encoded_input = tokenizer(samp, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bbb7b-222d-43a2-a230-028d38d43509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca577dd-7571-461a-ab77-b2e19b826b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)[0]\n",
    "res = model_output.flatten().tolist()\n",
    "#res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0af24-62f4-4d43-9eee-a56e16a19420",
   "metadata": {},
   "source": [
    "### Create model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88ddc9-54eb-4e03-83aa-6dd6760eb34a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir=\"tmp\"\n",
    "os.makedirs(save_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f690cd-b806-45a2-86fb-b4ed5e673a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(save_dir)\n",
    "model.save_pretrained(save_dir)\n",
    "model.config.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1475cd77-c2cc-4bc7-8d17-bda02f58adc0",
   "metadata": {},
   "source": [
    "### Create Inference Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63429094-95c0-4acd-b791-621cd8298e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf60054-92a7-4739-a484-b6f8ddaab793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile code/inference.py\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "def model_fn(model_dir):\n",
    "  # Load model from HuggingFace Hub\n",
    "  tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "  model = BertModel.from_pretrained(model_dir)\n",
    "  return model, tokenizer\n",
    "\n",
    "def predict_fn(data, model_and_tokenizer):\n",
    "    # destruct model and tokenizer\n",
    "    model, tokenizer = model_and_tokenizer\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    sentences = data.pop(\"inputs\", data)\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Model Inference\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)[0]\n",
    "    print(model_output)\n",
    "    print(type(model_output))\n",
    "    # return dictonary, which will be json serializable\n",
    "    return {\"vectors\": model_output.flatten().tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c4ae9-2a9e-495a-9139-a2c155c6e2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy inference.py into the code/ directory of the model directory.\n",
    "!cp -r code/ tmp/code/\n",
    "# create a model.tar.gz archive with all the model artifacts and the inference.py script.\n",
    "%cd tmp\n",
    "!tar zcvf model.tar.gz *\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b87669-5dc7-401f-9f38-3aef88a49cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "# create s3 uri\n",
    "s3_model_path = f\"s3://{sess.default_bucket()}/\"+\"bert-mars\"\n",
    "print(s3_model_path)\n",
    "\n",
    "# upload model.tar.gz\n",
    "s3_model_uri = S3Uploader.upload(local_path=\"tmp/model.tar.gz\",desired_s3_uri=s3_model_path)\n",
    "print(f\"model artifcats uploaded to {s3_model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836466cf-6a2d-4c28-a6bd-6a476f717a28",
   "metadata": {},
   "source": [
    "### Create Model and Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41166e-4d90-42c3-a7e6-c3e199aa0692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_model_uri,       # path to your model and script\n",
    "   role=role,                    # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.12\",  # transformers version used\n",
    "   pytorch_version=\"1.9\",        # pytorch version used\n",
    "   py_version='py38',            # python version used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef7912-13f0-45c2-b4f2-9a76165110dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deploy the endpoint endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,      # number of instances\n",
    "    instance_type=\"ml.c5.xlarge\" #instance type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bfad99-a6bc-4bd2-b1ff-1bb0f047326b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "\n",
    "embedding_gen_payload = json.dumps({'inputs': \"The company HuggingFace is based in New York City\"})\n",
    "response = runtime.invoke_endpoint(\n",
    "        EndpointName=predictor.endpoint_name,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=embedding_gen_payload)\n",
    "\n",
    "response['Body'].read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
