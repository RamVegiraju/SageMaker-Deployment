{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "---\n",
    "## <span style=\"color:orange\"> TensorFlow Image Classification on SageMaker </span>\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Background\n",
    "For our model, we train a smaller version of AlexNet CNN to classify images from the CIFAR-10 dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    " #### Prerequisites \n",
    " Choose Kernel for this notebook.<br>\n",
    " Under `Kernel` tab at the top of this notebook &#8594; `Choose kernel`, select `conda_python3` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tensorflow==2.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sagemaker.tensorflow.serving import TensorFlowModel\n",
    "from sagemaker.multidatamodel import MultiDataModel\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker import get_execution_role\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Setup Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using TensorFlow version: 2.3.0]\n",
      "[Using SageMaker version: 2.66.0]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using TensorFlow version: {tf.__version__}]')\n",
    "logger.info(f'[Using SageMaker version: {sagemaker.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Seed for Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Create Roles, Sessions and Data Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "TF_FRAMEWORK_VERSION = '2.3.0'\n",
    "BUCKET = sagemaker.Session().default_bucket()\n",
    "PREFIX = 'cv-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Train - CIFAR-10 Image Classification\n",
    "\n",
    "<p align=\"justify\">First, we will train a Convolutional Neural Network (CNN) model to classify images from the CIFAR-10 dataset. Image classification is the task of assigning a label to an image, from a predefined set of categories. CIFAR-10 is an established CV dataset used for object recognition. It is a subset of the 80 Million Tiny Images dataset and consists of 60,000 (32x32) color images containing 1 of 10 object classes, with 6,000 images per class.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### a) Load Data\n",
    "\n",
    "The first step is to load the pre-shuffled CIFAR-10 dataset into our train and test objects. Luckily, Keras provides the CIFAR dataset for us to load using the `load_data()` method. All we have to do is import keras.datasets and then load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X_train Shape: (50000, 32, 32, 3)\n",
      "y_train Shape: (50000, 1)\n",
      "X_test Shape : (10000, 32, 32, 3)\n",
      "y_test Shape : (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'X_train Shape: {X_train.shape}')\n",
    "logger.info(f'y_train Shape: {y_train.shape}')\n",
    "logger.info(f'X_test Shape : {X_test.shape}')\n",
    "logger.info(f'y_test Shape : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### c) Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Rescale \n",
    "Rescales the images by dividing the pixel values by 255: [0,255] ⇒ [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### One Hot Encode Target Labels\n",
    "One-hot encoding is a process by which categorical variables are converted into a numeric form. One-hot encoding converts the (1 × n) label vector to a label matrix of dimensions (10 × n), where n is the number of sample images. So, if we have 1,000 images in our dataset, the label vector will have the dimensions (1 × 1000). After one-hot encoding, the label matrix dimensions will be (1000 × 10). That’s why, when we define our network architecture in the next step, we will make the output softmax layer contain 10 nodes, where each node represents the probability of each class we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Split Data\n",
    "Break original train set further into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_validation = X_train[500:], X_train[:500]\n",
    "y_train, y_validation = y_train[500:], y_train[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Save to Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Create a local `data/cifar_10` directory to save the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = './data/cifar_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(DATASET_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Save train, validation and test sets to local `data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "np.save(f'{DATASET_PATH}/X_train.npy', X_train)\n",
    "np.save(f'{DATASET_PATH}/y_train.npy', y_train)\n",
    "np.save(f'{DATASET_PATH}/X_validation.npy', X_validation)\n",
    "np.save(f'{DATASET_PATH}/y_validation.npy', y_validation)\n",
    "np.save(f'{DATASET_PATH}/X_test.npy', X_test)\n",
    "np.save(f'{DATASET_PATH}/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Copy Datasets to S3\n",
    "Copy train, validation and test sets from the local dir to S3, since SageMaker expects datasets to be in S3 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/cifar_10/X_train.npy to s3://sagemaker-us-east-1-474422712127/cv-models/cifar_10/train/X_train.npy\n",
      "upload: data/cifar_10/y_train.npy to s3://sagemaker-us-east-1-474422712127/cv-models/cifar_10/train/y_train.npy\n",
      "upload: data/cifar_10/X_validation.npy to s3://sagemaker-us-east-1-474422712127/cv-models/cifar_10/validation/X_validation.npy\n",
      "upload: data/cifar_10/y_validation.npy to s3://sagemaker-us-east-1-474422712127/cv-models/cifar_10/validation/y_validation.npy\n",
      "upload: data/cifar_10/X_test.npy to s3://sagemaker-us-east-1-474422712127/cv-models/cifar_10/test/X_test.npy\n",
      "upload: data/cifar_10/y_test.npy to s3://sagemaker-us-east-1-474422712127/cv-models/cifar_10/test/y_test.npy\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./{DATASET_PATH}/X_train.npy s3://{BUCKET}/{PREFIX}/cifar_10/train/\n",
    "!aws s3 cp ./{DATASET_PATH}/y_train.npy s3://{BUCKET}/{PREFIX}/cifar_10/train/\n",
    "!aws s3 cp ./{DATASET_PATH}/X_validation.npy s3://{BUCKET}/{PREFIX}/cifar_10/validation/\n",
    "!aws s3 cp ./{DATASET_PATH}/y_validation.npy s3://{BUCKET}/{PREFIX}/cifar_10/validation/\n",
    "!aws s3 cp ./{DATASET_PATH}/X_test.npy s3://{BUCKET}/{PREFIX}/cifar_10/test/\n",
    "!aws s3 cp ./{DATASET_PATH}/y_test.npy s3://{BUCKET}/{PREFIX}/cifar_10/test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### d) Create Training Inputs \n",
    "Using the S3 locations of the datasets we saved in the previous step, create pointers to these datasets using the `TrainingInput`class from the SageMaker SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "train_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar_10/train', \n",
    "                            distribution='FullyReplicated', \n",
    "                            content_type='npy')\n",
    "validation_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar_10/validation', \n",
    "                                 distribution='FullyReplicated', \n",
    "                                 content_type='npy')\n",
    "test_input = TrainingInput(s3_data=f's3://{BUCKET}/{PREFIX}/cifar_10/test', \n",
    "                           distribution='FullyReplicated', \n",
    "                           content_type='npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "inputs = {'train': train_input, 'val': validation_input, 'test': test_input}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### e) Define Model Architecture & create Training Script\n",
    "\n",
    "We will build a small CNN consisting of three convolutional layers and two dense layers.<br>\n",
    "<b>Note:</b> We will use the ReLU activation function for all the hidden layers. In the last dense layer, we will use a softmax activation function with 10 nodes to return an array of 10 probability scores (summing to 1). Each score will be the probability that the current image belongs to our 10 image classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlayers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpreprocessing\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mimage\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ImageDataGenerator\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcallbacks\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ModelCheckpoint \n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Sequential\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_model\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m utils\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[37m# Set Log Level\u001b[39;49;00m\n",
      "os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mTF_CPP_MIN_LOG_LEVEL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[33m'\u001b[39;49;00m\u001b[33m3\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Seed for Reproducability \u001b[39;49;00m\n",
      "SEED = \u001b[34m123\u001b[39;49;00m\n",
      "np.random.seed(SEED)\n",
      "tf.random.set_seed(SEED)\n",
      "\n",
      "\u001b[37m# Setup Logger\u001b[39;49;00m\n",
      "logger = logging.getLogger(\u001b[33m'\u001b[39;49;00m\u001b[33msagemaker\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "logger.setLevel(logging.INFO)\n",
      "logger.addHandler(logging.StreamHandler())\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\n",
      "    parser = argparse.ArgumentParser() \n",
      "    \u001b[37m# Hyperparameters sent by the client are passed as command-line arguments to the script\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_DATA\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_OUTPUT\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--val\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_VAL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TEST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_train_data\u001b[39;49;00m(train_dir):\n",
      "    X_train = np.load(os.path.join(train_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mX_train.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_train = np.load(os.path.join(train_dir, \u001b[33m'\u001b[39;49;00m\u001b[33my_train.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mX_train: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mX_train.shape\u001b[33m}\u001b[39;49;00m\u001b[33m | y_train: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00my_train.shape\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m X_train, y_train\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_validation_data\u001b[39;49;00m(val_dir):\n",
      "    X_validation = np.load(os.path.join(val_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mX_validation.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_validation = np.load(os.path.join(val_dir, \u001b[33m'\u001b[39;49;00m\u001b[33my_validation.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mX_validation: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mX_validation.shape\u001b[33m}\u001b[39;49;00m\u001b[33m | y_validation:  \u001b[39;49;00m\u001b[33m{\u001b[39;49;00my_validation.shape\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m X_validation, y_validation\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_test_data\u001b[39;49;00m(test_dir):\n",
      "    X_test = np.load(os.path.join(test_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mX_test.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_test = np.load(os.path.join(test_dir, \u001b[33m'\u001b[39;49;00m\u001b[33my_test.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mX_test: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mX_test.shape\u001b[33m}\u001b[39;49;00m\u001b[33m | y_test:  \u001b[39;49;00m\u001b[33m{\u001b[39;49;00my_test.shape\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m X_test, y_test\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m[Using TensorFlow version: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtf.__version__\u001b[33m}\u001b[39;49;00m\u001b[33m]\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    DEVICE = \u001b[33m'\u001b[39;49;00m\u001b[33m/cpu:0\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    args, _ = parse_args()\n",
      "    epochs = args.epochs\n",
      "    \n",
      "    \u001b[37m# Load train, validation and test sets from S3\u001b[39;49;00m\n",
      "    X_train, y_train = get_train_data(args.train)\n",
      "    X_validation, y_validation = get_validation_data(args.val)\n",
      "    X_test, y_test = get_test_data(args.test)\n",
      "    \n",
      "    \u001b[34mwith\u001b[39;49;00m tf.device(DEVICE):\n",
      "        \u001b[37m# Data Augmentation\u001b[39;49;00m\n",
      "        TRAIN_BATCH_SIZE = \u001b[34m32\u001b[39;49;00m\n",
      "        data_generator = ImageDataGenerator(width_shift_range=\u001b[34m0.1\u001b[39;49;00m, height_shift_range=\u001b[34m0.1\u001b[39;49;00m, horizontal_flip=\u001b[34mTrue\u001b[39;49;00m)\n",
      "        train_iterator = data_generator.flow(X_train, y_train, batch_size=TRAIN_BATCH_SIZE)\n",
      "        \n",
      "        \u001b[37m# Define Model Architecture\u001b[39;49;00m\n",
      "        model = Sequential()\n",
      "        \n",
      "        \u001b[37m# CONVOLUTIONAL LAYER 1\u001b[39;49;00m\n",
      "        model.add(Conv2D(filters=\u001b[34m16\u001b[39;49;00m, kernel_size=\u001b[34m2\u001b[39;49;00m, padding=\u001b[33m'\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, input_shape=(\u001b[34m32\u001b[39;49;00m, \u001b[34m32\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m)))\n",
      "        model.add(BatchNormalization())\n",
      "        model.add(MaxPooling2D(pool_size=\u001b[34m2\u001b[39;49;00m))\n",
      "\n",
      "        \u001b[37m# CONVOLUTIONAL LAYER 1\u001b[39;49;00m\n",
      "        model.add(Conv2D(filters=\u001b[34m32\u001b[39;49;00m, kernel_size=\u001b[34m2\u001b[39;49;00m, padding=\u001b[33m'\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "        model.add(BatchNormalization())\n",
      "        model.add(MaxPooling2D(pool_size=\u001b[34m2\u001b[39;49;00m))\n",
      "\n",
      "        \u001b[37m# CONVOLUTIONAL LAYER 3\u001b[39;49;00m\n",
      "        model.add(Conv2D(filters=\u001b[34m64\u001b[39;49;00m, kernel_size=\u001b[34m2\u001b[39;49;00m, padding=\u001b[33m'\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "        model.add(BatchNormalization())\n",
      "        model.add(MaxPooling2D(pool_size=\u001b[34m2\u001b[39;49;00m))\n",
      "        model.add(Dropout(\u001b[34m0.3\u001b[39;49;00m))\n",
      "\n",
      "        \u001b[37m# FULLY CONNECTED LAYER \u001b[39;49;00m\n",
      "        model.add(Flatten())\n",
      "        model.add(Dense(\u001b[34m500\u001b[39;49;00m, activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "        model.add(Dropout(\u001b[34m0.4\u001b[39;49;00m))\n",
      "        model.add(Dense(\u001b[34m10\u001b[39;49;00m, activation=\u001b[33m'\u001b[39;49;00m\u001b[33msoftmax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "        model.summary()\n",
      "        \n",
      "        \u001b[37m# Compile Model\u001b[39;49;00m\n",
      "        model.compile(loss=\u001b[33m'\u001b[39;49;00m\u001b[33mcategorical_crossentropy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, optimizer=\u001b[33m'\u001b[39;49;00m\u001b[33madam\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, metrics=[\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "        \n",
      "        \u001b[37m# Train Model\u001b[39;49;00m\n",
      "        BATCH_SIZE = \u001b[34m32\u001b[39;49;00m\n",
      "        STEPS_PER_EPOCH = \u001b[36mint\u001b[39;49;00m(X_train.shape[\u001b[34m0\u001b[39;49;00m]/TRAIN_BATCH_SIZE)\n",
      "        \n",
      "        model.fit(train_iterator, \n",
      "                  steps_per_epoch=STEPS_PER_EPOCH, \n",
      "                  batch_size=BATCH_SIZE, \n",
      "                  epochs=epochs, \n",
      "                  validation_data=(X_validation, y_validation), \n",
      "                  callbacks=[], \n",
      "                  verbose=\u001b[34m2\u001b[39;49;00m, \n",
      "                  shuffle=\u001b[34mTrue\u001b[39;49;00m)\n",
      "        \n",
      "        \u001b[37m# Evaluate on Test Set\u001b[39;49;00m\n",
      "        result = model.evaluate(X_test, y_test, verbose=\u001b[34m1\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mTest Accuracy: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mresult[\u001b[34m1\u001b[39;49;00m]\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        \n",
      "        \u001b[37m# Save Model\u001b[39;49;00m\n",
      "        model.save(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.model_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize cifar_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### f) Create a TensorFlow Estimator & fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'cifar-10'\n",
    "hyperparameters = {'epochs': 30}\n",
    "estimator_parameters = {'entry_point':'cifar_train.py',\n",
    "                        'instance_type': 'ml.m5.2xlarge',\n",
    "                        'instance_count': 1,\n",
    "                        'model_dir': f'/opt/ml/model',\n",
    "                        'role': role,\n",
    "                        'hyperparameters': hyperparameters,\n",
    "                        'output_path': f's3://{BUCKET}/{PREFIX}/cifar_10/out',\n",
    "                        'base_job_name': f'mme-cv-{model_name}',\n",
    "                        'framework_version': TF_FRAMEWORK_VERSION,\n",
    "                        'py_version': 'py37',\n",
    "                        'script_mode': True}\n",
    "estimator_1 = TensorFlow(**estimator_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-10 02:42:20 Starting - Starting the training job...\n",
      "2021-11-10 02:42:43 Starting - Launching requested ML instancesProfilerReport-1636512140: InProgress\n",
      "...\n",
      "2021-11-10 02:43:20 Starting - Preparing the instances for training.........\n",
      "2021-11-10 02:44:51 Downloading - Downloading input data...\n",
      "2021-11-10 02:45:16 Training - Downloading the training image...\n",
      "2021-11-10 02:45:44 Training - Training image download completed. Training in progress.\u001b[34m2021-11-10 02:45:35,151 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-11-10 02:45:35,159 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-10 02:45:35,463 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-10 02:45:35,569 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-10 02:45:35,587 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-10 02:45:35,598 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"val\": \"/opt/ml/input/data/val\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/ml/model\",\n",
      "        \"epochs\": 30\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"val\": {\n",
      "            \"ContentType\": \"npy\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"ContentType\": \"npy\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"npy\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"mme-cv-cifar-10-2021-11-10-02-42-20-205\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-474422712127/mme-cv-cifar-10-2021-11-10-02-42-20-205/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar_train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":30,\"model_dir\":\"/opt/ml/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-474422712127/mme-cv-cifar-10-2021-11-10-02-42-20-205/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":30,\"model_dir\":\"/opt/ml/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"ContentType\":\"npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mme-cv-cifar-10-2021-11-10-02-42-20-205\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-474422712127/mme-cv-cifar-10-2021-11-10-02-42-20-205/source/sourcedir.tar.gz\",\"module_name\":\"cifar_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"30\",\"--model_dir\",\"/opt/ml/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=30\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 cifar_train.py --epochs 30 --model_dir /opt/ml/model\u001b[0m\n",
      "\u001b[34mModel: \"sequential\"\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mconv2d (Conv2D)              (None, 32, 32, 16)        208       \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization (BatchNo (None, 32, 32, 16)        64        \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_1 (Conv2D)            (None, 16, 16, 32)        2080      \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_1 (Batch (None, 16, 16, 32)        128       \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_2 (Conv2D)            (None, 8, 8, 64)          8256      \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_2 (Batch (None, 8, 8, 64)          256       \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout (Dropout)            (None, 4, 4, 64)          0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mflatten (Flatten)            (None, 1024)              0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense (Dense)                (None, 500)               512500    \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout_1 (Dropout)          (None, 500)               0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_1 (Dense)              (None, 10)                5010      \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 528,502\u001b[0m\n",
      "\u001b[34mTrainable params: 528,278\u001b[0m\n",
      "\u001b[34mNon-trainable params: 224\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34m[2021-11-10 02:45:40.996 ip-10-0-246-146.ec2.internal:26 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-11-10 02:45:40.997 ip-10-0-246-146.ec2.internal:26 INFO hook.py:193] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-11-10 02:45:40.997 ip-10-0-246-146.ec2.internal:26 INFO hook.py:238] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-11-10 02:45:40.997 ip-10-0-246-146.ec2.internal:26 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-11-10 02:45:41.129 ip-10-0-246-146.ec2.internal:26 INFO hook.py:398] Monitoring the collections: losses, sm_metrics, metrics\u001b[0m\n",
      "\u001b[34mEpoch 1/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 47s - loss: 1.7638 - accuracy: 0.3684 - val_loss: 1.6998 - val_accuracy: 0.3780\u001b[0m\n",
      "\u001b[34mEpoch 2/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 46s - loss: 1.5335 - accuracy: 0.4473 - val_loss: 1.2858 - val_accuracy: 0.5520\u001b[0m\n",
      "\u001b[34mEpoch 3/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 44s - loss: 1.4594 - accuracy: 0.4731 - val_loss: 1.2773 - val_accuracy: 0.5260\u001b[0m\n",
      "\u001b[34mEpoch 4/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 46s - loss: 1.4165 - accuracy: 0.4925 - val_loss: 1.3390 - val_accuracy: 0.5220\u001b[0m\n",
      "\u001b[34mEpoch 5/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 46s - loss: 1.4001 - accuracy: 0.4975 - val_loss: 1.1684 - val_accuracy: 0.5740\u001b[0m\n",
      "\u001b[34mEpoch 6/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 45s - loss: 1.3657 - accuracy: 0.5124 - val_loss: 1.1838 - val_accuracy: 0.5820\u001b[0m\n",
      "\u001b[34mEpoch 7/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 44s - loss: 1.3526 - accuracy: 0.5176 - val_loss: 1.2364 - val_accuracy: 0.5780\u001b[0m\n",
      "\u001b[34mEpoch 8/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 45s - loss: 1.3293 - accuracy: 0.5249 - val_loss: 1.5549 - val_accuracy: 0.4500\u001b[0m\n",
      "\u001b[34mEpoch 9/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 46s - loss: 1.3301 - accuracy: 0.5254 - val_loss: 1.2950 - val_accuracy: 0.5440\u001b[0m\n",
      "\u001b[34mEpoch 10/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 45s - loss: 1.3089 - accuracy: 0.5351 - val_loss: 1.3982 - val_accuracy: 0.5040\u001b[0m\n",
      "\u001b[34mEpoch 11/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 45s - loss: 1.2839 - accuracy: 0.5437 - val_loss: 1.1792 - val_accuracy: 0.5820\u001b[0m\n",
      "\u001b[34mEpoch 12/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 45s - loss: 1.2871 - accuracy: 0.5418 - val_loss: 1.0354 - val_accuracy: 0.6320\u001b[0m\n",
      "\u001b[34mEpoch 13/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 45s - loss: 1.2775 - accuracy: 0.5467 - val_loss: 1.0890 - val_accuracy: 0.6200\u001b[0m\n",
      "\u001b[34mEpoch 14/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 45s - loss: 1.2705 - accuracy: 0.5474 - val_loss: 1.1690 - val_accuracy: 0.5940\u001b[0m\n",
      "\u001b[34mEpoch 15/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 44s - loss: 1.2779 - accuracy: 0.5484 - val_loss: 1.0984 - val_accuracy: 0.6000\u001b[0m\n",
      "\u001b[34mEpoch 16/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 46s - loss: 1.2699 - accuracy: 0.5488 - val_loss: 1.1338 - val_accuracy: 0.6020\u001b[0m\n",
      "\u001b[34mEpoch 17/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 45s - loss: 1.2508 - accuracy: 0.5571 - val_loss: 1.1248 - val_accuracy: 0.6020\u001b[0m\n",
      "\u001b[34mEpoch 18/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 46s - loss: 1.2568 - accuracy: 0.5542 - val_loss: 1.1600 - val_accuracy: 0.5820\u001b[0m\n",
      "\u001b[34mEpoch 19/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 43s - loss: 1.2431 - accuracy: 0.5558 - val_loss: 1.1429 - val_accuracy: 0.5820\u001b[0m\n",
      "\u001b[34mEpoch 20/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 45s - loss: 1.2240 - accuracy: 0.5655 - val_loss: 1.0732 - val_accuracy: 0.6180\u001b[0m\n",
      "\u001b[34mEpoch 21/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 44s - loss: 1.2175 - accuracy: 0.5692 - val_loss: 1.0491 - val_accuracy: 0.6480\u001b[0m\n",
      "\u001b[34mEpoch 22/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 45s - loss: 1.2052 - accuracy: 0.5727 - val_loss: 0.9986 - val_accuracy: 0.6400\u001b[0m\n",
      "\u001b[34mEpoch 23/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 43s - loss: 1.1994 - accuracy: 0.5770 - val_loss: 1.0016 - val_accuracy: 0.6460\u001b[0m\n",
      "\u001b[34mEpoch 24/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 46s - loss: 1.2048 - accuracy: 0.5719 - val_loss: 1.0701 - val_accuracy: 0.6060\u001b[0m\n",
      "\u001b[34mEpoch 25/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 46s - loss: 1.1886 - accuracy: 0.5798 - val_loss: 1.1199 - val_accuracy: 0.6060\u001b[0m\n",
      "\u001b[34mEpoch 26/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 45s - loss: 1.1890 - accuracy: 0.5803 - val_loss: 1.0245 - val_accuracy: 0.6340\u001b[0m\n",
      "\u001b[34mEpoch 27/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 43s - loss: 1.1978 - accuracy: 0.5753 - val_loss: 0.9987 - val_accuracy: 0.6740\u001b[0m\n",
      "\u001b[34mEpoch 28/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 46s - loss: 1.2051 - accuracy: 0.5746 - val_loss: 1.0395 - val_accuracy: 0.6460\u001b[0m\n",
      "\u001b[34mEpoch 29/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 46s - loss: 1.1972 - accuracy: 0.5747 - val_loss: 1.0385 - val_accuracy: 0.6420\u001b[0m\n",
      "\u001b[34mEpoch 30/30\u001b[0m\n",
      "\u001b[34m1546/1546 - 46s - loss: 1.2054 - accuracy: 0.5741 - val_loss: 1.0827 - val_accuracy: 0.6020\u001b[0m\n",
      "\u001b[34m#015  1/313 [..............................] - ETA: 0s - loss: 1.0387 - accuracy: 0.5625#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 16/313 [>.............................] - ETA: 0s - loss: 1.1908 - accuracy: 0.5742#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 32/313 [==>...........................] - ETA: 0s - loss: 1.1308 - accuracy: 0.5977#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 44/313 [===>..........................] - ETA: 0s - loss: 1.1264 - accuracy: 0.5938#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 61/313 [====>.........................] - ETA: 0s - loss: 1.1292 - accuracy: 0.5861#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 78/313 [======>.......................] - ETA: 0s - loss: 1.1142 - accuracy: 0.5970#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 95/313 [========>.....................] - ETA: 0s - loss: 1.1252 - accuracy: 0.5934#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015112/313 [=========>....................] - ETA: 0s - loss: 1.1243 - accuracy: 0.5954#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015129/313 [===========>..................] - ETA: 0s - loss: 1.1134 - accuracy: 0.6005#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015146/313 [============>.................] - ETA: 0s - loss: 1.1107 - accuracy: 0.6030#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015163/313 [==============>...............] - ETA: 0s - loss: 1.1055 - accuracy: 0.6045#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015180/313 [================>.............] - ETA: 0s - loss: 1.1073 - accuracy: 0.6021#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015197/313 [=================>............] - ETA: 0s - loss: 1.1136 - accuracy: 0.6014#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015215/313 [===================>..........] - ETA: 0s - loss: 1.1184 - accuracy: 0.5978#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015232/313 [=====================>........] - ETA: 0s - loss: 1.1202 - accuracy: 0.5978#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015250/313 [======================>.......] - ETA: 0s - loss: 1.1200 - accuracy: 0.5982#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015269/313 [========================>.....] - ETA: 0s - loss: 1.1171 - accuracy: 0.5992#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015285/313 [==========================>...] - ETA: 0s - loss: 1.1189 - accuracy: 0.5984#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015303/313 [============================>.] - ETA: 0s - loss: 1.1149 - accuracy: 0.5996#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015313/313 [==============================] - 1s 3ms/step - loss: 1.1185 - accuracy: 0.5980\u001b[0m\n",
      "\u001b[34mTest Accuracy: 0.5979999899864197\u001b[0m\n",
      "\u001b[34m2021-11-10 03:08:19,826 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-11-10 03:08:32 Uploading - Uploading generated training model\n",
      "2021-11-10 03:08:32 Completed - Training job completed\n",
      "Training seconds: 1421\n",
      "Billable seconds: 1421\n"
     ]
    }
   ],
   "source": [
    "estimator_1.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator_1.deploy(initial_instance_count=1,\n",
    "                       instance_type='ml.m5.2xlarge',\n",
    "                       endpoint_name=f'tensorflow-cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import Image\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "CIFAR10_LABELS = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('./data/cifar_10/raw_images/airplane.png', target_size=(32, 32))\n",
    "data = img_to_array(img)\n",
    "data = data.astype('float32')\n",
    "data = data / 255.0\n",
    "data = data.reshape(1, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'instances': data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: [airplane]\n"
     ]
    }
   ],
   "source": [
    "resp = predictor.predict(payload)\n",
    "predicted_label = CIFAR10_LABELS[np.argmax(resp)]\n",
    "print(f'Predicted Label: [{predicted_label}]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
