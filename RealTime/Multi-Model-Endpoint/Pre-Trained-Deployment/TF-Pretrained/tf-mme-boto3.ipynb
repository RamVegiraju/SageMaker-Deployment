{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb24605",
   "metadata": {},
   "source": [
    "# TF MME W/ Boto3\n",
    "\n",
    "<b>Setting</b>: conda_tf2_p38 & Classic Notebook Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5baab11",
   "metadata": {},
   "source": [
    "## Local Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3beb1382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting local_tf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile local_tf.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "#ANN Model\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_shape=(13,), activation='relu'))\n",
    "    model.add(Dense(28, activation='relu'))\n",
    "    model.add(Dense(13, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "#Load data\n",
    "boston = datasets.load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['MEDV'] = boston.target \n",
    "\n",
    "#Split Model\n",
    "X = df.drop(['MEDV'], axis = 1) \n",
    "y = df['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42)\n",
    "\n",
    "#minimum epochs 15\n",
    "model = createModel()\n",
    "monitor_val_acc = EarlyStopping(monitor = 'val_loss', patience=15)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[monitor_val_acc], epochs=5)\n",
    "model.save('0000001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671842e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 1s 14ms/step - loss: 877.9043 - val_loss: 305.3114\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 155.8673 - val_loss: 94.3146\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 94.3202 - val_loss: 76.7769\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 77.9523 - val_loss: 64.1925\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 74.8727 - val_loss: 62.3719\n"
     ]
    }
   ],
   "source": [
    "!python local_tf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c3cf4",
   "metadata": {},
   "source": [
    "## Package for SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866185fa",
   "metadata": {},
   "source": [
    "### Script for TF Serving to control pre/post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0daf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "import json\n",
    "\n",
    "def input_handler(data, context):\n",
    "    \"\"\" Pre-process request input before it is sent to TensorFlow Serving REST API\n",
    "    Args:\n",
    "        data (obj): the request data, in format of dict or string\n",
    "        context (Context): an object containing request and configuration details\n",
    "    Returns:\n",
    "        (dict): a JSON-serializable dict that contains request body and headers\n",
    "    \"\"\"\n",
    "    if context.request_content_type == 'application/json':\n",
    "        # pass through json (assumes it's correctly formed)\n",
    "        d = data.read().decode('utf-8')\n",
    "        print(\"------------\")\n",
    "        print(d)\n",
    "        print(type(d))\n",
    "        print(\"------------\")\n",
    "        return d if len(d) else ''\n",
    "\n",
    "    if context.request_content_type == 'text/csv':\n",
    "        # very simple csv handler\n",
    "        return json.dumps({\n",
    "            'instances': [float(x) for x in data.read().decode('utf-8').split(',')]\n",
    "        })\n",
    "\n",
    "    raise ValueError('{{\"error\": \"unsupported content type {}\"}}'.format(\n",
    "        context.request_content_type or \"unknown\"))\n",
    "\n",
    "\n",
    "def output_handler(data, context):\n",
    "    \"\"\"Post-process TensorFlow Serving output before it is returned to the client.\n",
    "    Args:\n",
    "        data (obj): the TensorFlow serving response\n",
    "        context (Context): an object containing request and configuration details\n",
    "    Returns:\n",
    "        (bytes, string): data to return to client, response content type\n",
    "    \"\"\"\n",
    "    if data.status_code != 200:\n",
    "        raise ValueError(data.content.decode('utf-8'))\n",
    "\n",
    "    response_content_type = context.accept_header\n",
    "    print(\"-------\")\n",
    "    print(data)\n",
    "    print(type(data))\n",
    "    print(\"-----\")\n",
    "    prediction = data.content\n",
    "    return prediction, response_content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c22e4bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "#Setup\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "#role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "540c1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy inference.py into a code file for sm to recognize\n",
    "createDirectory = \"mkdir code\"\n",
    "copyInference = \"cp inference.py code\"\n",
    "p1 = subprocess.call(createDirectory, shell=True)\n",
    "p2 = subprocess.call(copyInference, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b668a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tar file with model artifacts\n",
    "bashCommand = \"tar -cvpzf model.tar.gz ./0000001\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc322881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tar ball for inference code, inference.py is consistent across all models in an MME\n",
    "bashCommand = \"tar -cvpzf source.tar.gz inference.py\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2870187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-474422712127\n"
     ]
    }
   ],
   "source": [
    "#Bucket for model artifacts\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "print(default_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a73104",
   "metadata": {},
   "source": [
    "### Make Copies Of Model Data In S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2345dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "for i in range(0,5):\n",
    "    with open(\"model.tar.gz\", \"rb\") as f:\n",
    "        s3.upload_fileobj(f, default_bucket, \"mme-tensorflow/tf-{}.tar.gz\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46dcf664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 20:11:22      25072 tf-0.tar.gz\n",
      "2022-08-04 20:11:22      25072 tf-1.tar.gz\n",
      "2022-08-04 20:11:22      25072 tf-2.tar.gz\n",
      "2022-08-04 20:11:22      25072 tf-3.tar.gz\n",
      "2022-08-04 20:11:22      25072 tf-4.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://{default_bucket}/mme-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "697d6cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./source.tar.gz to s3://sagemaker-us-east-1-474422712127/mme-tf-inf-script/source.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp source.tar.gz s3://{default_bucket}/mme-tf-inf-script/source.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61e84cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 20:11:23        790 source.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://{default_bucket}/mme-tf-inf-script/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "095ef2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-474422712127/mme-tf-inf-script/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dir = 's3://{}/mme-tf-inf-script/'.format(default_bucket)\n",
    "source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70a86e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 20:11:23        790 source.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {source_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a7fc6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = 's3://{}/mme-tensorflow/'.format(default_bucket) ## MODEL S3 URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0ada480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 20:11:22      25072 tf-0.tar.gz\n",
      "2022-08-04 20:11:22      25072 tf-1.tar.gz\n",
      "2022-08-04 20:11:22      25072 tf-2.tar.gz\n",
      "2022-08-04 20:11:22      25072 tf-3.tar.gz\n",
      "2022-08-04 20:11:22      25072 tf-4.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {model_url}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b373dc",
   "metadata": {},
   "source": [
    "### Retrieve Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5195b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.0-cpu'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve tf image\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=\"us-east-1\",\n",
    "    version=\"2.3.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    image_scope=\"inference\"\n",
    ")\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5dc13",
   "metadata": {},
   "source": [
    "### SageMaker Model Entity Creation\n",
    "\n",
    "API Call: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e82ae1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: mme-tf2022-08-04-20-11-24\n",
      "Model data Url: s3://sagemaker-us-east-1-474422712127/mme-tensorflow/\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:474422712127:model/mme-tf2022-08-04-20-11-24\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "model_name = 'mme-tf' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "print('Model name: ' + model_name)\n",
    "print('Model data Url: ' + model_url)\n",
    "\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            \"Image\": image_uri,\n",
    "            \"Mode\": \"MultiModel\",\n",
    "            \"ModelDataUrl\": model_url,\n",
    "            \"Environment\": {'SAGEMAKER_SUBMIT_DIRECTORY': source_dir,\n",
    "                           'SAGEMAKER_PROGRAM': 'inference.py'} \n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef05137",
   "metadata": {},
   "source": [
    "### Endpoint Config Creation\n",
    "\n",
    "API Call: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "542bb8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration Arn: arn:aws:sagemaker:us-east-1:474422712127:endpoint-config/mme-tf2022-08-04-20-11-25\n"
     ]
    }
   ],
   "source": [
    "#Step 2: EPC Creation\n",
    "tf_epc_name = \"mme-tf\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=tf_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"tfvariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.c5.large\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0e4c3",
   "metadata": {},
   "source": [
    "### Endpoint Creation\n",
    "\n",
    "API Call: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9b8b86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:474422712127:endpoint/mme-tf2022-08-04-20-11-25\n"
     ]
    }
   ],
   "source": [
    "#Step 3: EP Creation\n",
    "endpoint_name = \"mme-tf\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=tf_epc_name,\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "171f1858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n",
      "{'EndpointName': 'mme-tf2022-08-04-20-11-25', 'EndpointArn': 'arn:aws:sagemaker:us-east-1:474422712127:endpoint/mme-tf2022-08-04-20-11-25', 'EndpointConfigName': 'mme-tf2022-08-04-20-11-25', 'ProductionVariants': [{'VariantName': 'tfvariant', 'DeployedImages': [{'SpecifiedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.0-cpu', 'ResolvedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference@sha256:91ebb7428846c5f7b515d5d9b8389a14c73d0c5d02657f4a6413592124333278', 'ResolutionTime': datetime.datetime(2022, 8, 4, 20, 11, 27, 463000, tzinfo=tzlocal())}], 'CurrentWeight': 1.0, 'DesiredWeight': 1.0, 'CurrentInstanceCount': 1, 'DesiredInstanceCount': 1}], 'EndpointStatus': 'InService', 'CreationTime': datetime.datetime(2022, 8, 4, 20, 11, 25, 508000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 8, 4, 20, 17, 42, 272000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '9462f02a-3057-40d1-a9aa-3de7e41d41ee', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '9462f02a-3057-40d1-a9aa-3de7e41d41ee', 'content-type': 'application/x-amz-json-1.1', 'content-length': '729', 'date': 'Thu, 04 Aug 2022 20:17:42 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "#Monitor creation\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b630e1e",
   "metadata": {},
   "source": [
    "### Invoke MME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6978106d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load data\n",
    "boston = datasets.load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['MEDV'] = boston.target \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c139dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': [[0.00632, 18.0, 2.31, 0.0, 0.538, 6.575, 65.2, 4.09, 1.0, 296.0, 15.3, 396.9, 4.98]]}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "import pandas as pd\n",
    "\n",
    "test = df[:1]\n",
    "testX = test.drop(\"MEDV\", axis=1)\n",
    "testX = testX[:1].values.tolist()\n",
    "sampInput = {\"inputs\": testX}\n",
    "print(sampInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "596fbd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[26.0735073]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime_sm_client = boto3.client(service_name='sagemaker-runtime')\n",
    "jsons = JSONSerializer()\n",
    "content_type = \"application/json\"\n",
    "payload = jsons.serialize(sampInput)\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=payload,\n",
    "        ContentType=content_type,\n",
    "        TargetModel = \"tf-1.tar.gz\")\n",
    "result = json.loads(response['Body'].read().decode())['outputs']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfa09769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-0.tar.gz\n",
      "[[26.0735073]]\n",
      "tf-1.tar.gz\n",
      "[[26.0735073]]\n",
      "tf-2.tar.gz\n",
      "[[26.0735073]]\n",
      "tf-3.tar.gz\n",
      "[[26.0735073]]\n",
      "tf-4.tar.gz\n",
      "[[26.0735073]]\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,5):\n",
    "    target_model = \"tf-{}.tar.gz\".format(i)\n",
    "    print(target_model)\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=payload,\n",
    "        ContentType=content_type,\n",
    "        TargetModel = target_model)\n",
    "    print(json.loads(response['Body'].read().decode())['outputs'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p38",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
