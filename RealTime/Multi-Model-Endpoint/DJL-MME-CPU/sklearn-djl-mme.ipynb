{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7c1932-9c6b-406a-aa0b-8c4f6a065902",
   "metadata": {},
   "source": [
    "## DJL MME SKLearn Regression Example\n",
    "\n",
    "In this example we will train a dummy SKLearn Regression model, make a 1000 copies to scale up a sample MME Endpoint with DJL Serving as the backend on a CPU based instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b12704-47f2-42b7-a864-dae31dbbd49d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39578dcf-0ea4-4806-b5ba-6ebc88b0993a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "s3_model_prefix = \"djl-mme-sklearn-regression\" \n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0780742-c33e-4183-bfa8-998d8cc8a420",
   "metadata": {},
   "source": [
    "### Local Model Training\n",
    "\n",
    "We will train a sample Linear Regression Model on some dummy numpy data to create our joblib artifact we need for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a954d-0b59-4041-bea9-6c8db6c8091e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe131d-d67d-430a-880c-61521860b5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate dummy data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2 * X + 1 + 0.1 * np.random.randn(100, 1)  \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56405e0e-7872-4347-b949-c53b3795a606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "import joblib\n",
    "model_filename = \"model.joblib\"\n",
    "joblib.dump(model, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a285f-2d78-44aa-a07f-42705d7764ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serialized_model = joblib.load(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8a683-0ae8-4441-bc84-1b54e6c17997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample inference\n",
    "payload = [[0.5]]\n",
    "res = serialized_model.predict(payload).tolist()[0]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39c127-d87d-4ebf-b270-ebf9ba88bdee",
   "metadata": {},
   "source": [
    "### DJL Artifact Creation\n",
    "\n",
    "We now have our model artifact, but we need the following for our DJL Serving Engine\n",
    "\n",
    "- model.py: Inference script with custom model loading + pre/processing code\n",
    "- requirements.txt: Additional dependencies, in this case we need to install sklearn and numpy\n",
    "- serving.properties: Environment variables for DJL Serving, can adjust number of workers here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65061f1-739f-467e-a147-ac932a50bf35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "#!/usr/bin/env python\n",
    "#\n",
    "# Copyright 2021 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file\n",
    "# except in compliance with the License. A copy of the License is located at\n",
    "#\n",
    "# http://aws.amazon.com/apache2.0/\n",
    "#\n",
    "# or in the \"LICENSE.txt\" file accompanying this file. This file is distributed on an \"AS IS\"\n",
    "# BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express or implied. See the License for\n",
    "# the specific language governing permissions and limitations under the License.\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import joblib\n",
    "from djl_python import Input\n",
    "from djl_python import Output\n",
    "\n",
    "\n",
    "class SKLearnRegressor(object):\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, properties: dict):\n",
    "        \"\"\"\n",
    "        Initialize model.\n",
    "        \"\"\"\n",
    "        print(os.listdir())\n",
    "        if os.path.exists(\"model.joblib\"):\n",
    "            self.model = joblib.load(os.path.join(\"model.joblib\"))\n",
    "        else:\n",
    "            raise ValueError(\"Expecting a model.joblib artifact for SKLearn Model Loading\")\n",
    "        self.initialized = True\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        \"\"\"\n",
    "        Custom service entry point function.\n",
    "\n",
    "        :param inputs: the Input object holds a list of numpy array\n",
    "        :return: the Output object to be send back\n",
    "        \"\"\"\n",
    "\n",
    "        #sample input: [[0.5]]\n",
    "        \n",
    "        try:\n",
    "            data = inputs.get_as_json()\n",
    "            print(data)\n",
    "            print(type(data))\n",
    "            res = self.model.predict(data).tolist()[0]\n",
    "            outputs = Output()\n",
    "            outputs.add_as_json(res)\n",
    "        except Exception as e:\n",
    "            logging.exception(\"inference failed\")\n",
    "            # error handling\n",
    "            outputs = Output().error(str(e))\n",
    "        \n",
    "        print(outputs)\n",
    "        print(type(outputs))\n",
    "        print(\"Returning inference---------\")\n",
    "        return outputs\n",
    "\n",
    "\n",
    "_service = SKLearnRegressor()\n",
    "\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    \"\"\"\n",
    "    Default handler function\n",
    "    \"\"\"\n",
    "    if not _service.initialized:\n",
    "        # stateful model\n",
    "        _service.initialize(inputs.get_properties())\n",
    "    \n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "\n",
    "    return _service.inference(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f6519-0707-4346-8068-1080daff93b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "numpy==1.22.3\n",
    "joblib\n",
    "scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0787d46b-be2e-439f-93f7-93e500e2ea12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "# idle time in seconds before the worker thread is scaled down, the default is \n",
    "max_idle_time=600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12e09a-0806-45e4-a528-f369e819ba56",
   "metadata": {},
   "source": [
    "### Tarball Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f404b6f-edbb-4091-9118-46cafbba94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build tar file with model data + inference code, replace this cell with your model.joblib\n",
    "bashCommand = \"tar -cvpzf model.tar.gz model.joblib requirements.txt model.py serving.properties\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c5eef6-181c-489d-ac68-04c7b9033d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# we make a 1000 copies of the tarball as a dummy, you can replace this with your actual model.joblibs in tarball\n",
    "for i in range(1000):\n",
    "    with open(\"model.tar.gz\", \"rb\") as f:\n",
    "        s3_client.upload_fileobj(f, bucket, \"{}/sklearn-{}.tar.gz\".format(s3_model_prefix,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc6b38-266b-40b2-a2fd-3e6c3dcc7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mme_artifacts = \"s3://{}/{}/\".format(bucket, s3_model_prefix)\n",
    "mme_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a1c3d4-220a-4c07-bd70-51ce45203268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify all 1000 tar balls are present\n",
    "!aws s3 ls {mme_artifacts}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f8c01-6ecb-46a1-9117-80b1eafcad6e",
   "metadata": {},
   "source": [
    "### MME Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81858fe-ca17-4acc-b4c1-316b1458a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace this with your ECR image URI based off of your region, we are utilizing the CPU image here\n",
    "inference_image_uri = '474422712127.dkr.ecr.us-east-1.amazonaws.com/djl-serving-cpu:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7ebb8-d504-4db7-bc2e-8000aa0a4a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mme_model_name = \"sklearn-djl-mme\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name: \" + mme_model_name)\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=mme_model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\"Image\": inference_image_uri, \"Mode\": \"MultiModel\", \"ModelDataUrl\": mme_artifacts},\n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9fd99-61c3-4c66-a3d7-29608f9f3578",
   "metadata": {},
   "source": [
    "### MME Endpoint Config Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37694fb-53b5-48b6-b8be-8e5458916b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: EPC Creation\n",
    "mme_epc_name = \"sklearn-djl-mme-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=mme_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"sklearnvariant\",\n",
    "            \"ModelName\": mme_model_name,\n",
    "            \"InstanceType\": \"ml.c5d.18xlarge\",\n",
    "            \"InitialInstanceCount\": 20\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75965fc8-9e52-4e7d-baab-338ccf697ed3",
   "metadata": {},
   "source": [
    "### MME Endpoint Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a2fe9-9499-41fc-8a23-30d5585aa0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: EP Creation\n",
    "mme_endpoint_name = \"sklearn-djl-ep-mme\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=mme_endpoint_name,\n",
    "    EndpointConfigName=mme_epc_name,\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f1419-5e8a-4977-afe0-3bb36b7197aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monitor creation\n",
    "describe_endpoint_response = sm_client.describe_endpoint(EndpointName=mme_endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = sm_client.describe_endpoint(EndpointName=mme_endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9da917-0636-4410-8b4f-708ad737eee6",
   "metadata": {},
   "source": [
    "### Sample Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2727f8a-6a37-4bcd-9ab8-ad0d2152fe6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "content_type = \"application/json\"\n",
    "request_body = '[[0.5]]' #replace with your request body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802afeb1-5d60-48f8-b9a4-eb087be15f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = smr_client.invoke_endpoint(\n",
    "    EndpointName=mme_endpoint_name,\n",
    "    ContentType=content_type,\n",
    "    TargetModel = \"sklearn-902.tar.gz\",\n",
    "    Body=request_body)\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27def3a-402d-401b-bb6f-8306ddd6a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(100):\n",
    "    response = smr_client.invoke_endpoint(\n",
    "    EndpointName=mme_endpoint_name,\n",
    "    ContentType=content_type,\n",
    "    TargetModel = \"sklearn-902.tar.gz\",\n",
    "    Body=request_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc7673-21cf-4bea-8906-d113be37bebd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9305592f-db53-4bbe-a4f4-46d182f0138b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName = mme_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
