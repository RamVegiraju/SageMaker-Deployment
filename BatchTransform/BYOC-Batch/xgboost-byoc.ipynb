{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "867ce834-7a31-402e-990b-e3916ebf866c",
   "metadata": {},
   "source": [
    "## Bring Your Own Container Batch Inference\n",
    "\n",
    "In this example we take a look at how we can bring an open source XGBoost pre-trained model to Batch Inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a56681a-75d2-412c-9286-9a1324928595",
   "metadata": {},
   "source": [
    "### Local Model Creation + Training\n",
    "\n",
    "We will first locally generate a sample xgboost.json artifact to use in our container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f37d4-ec30-4dd5-b3f0-d402a6b44f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18ddbe-cd56-4c12-8930-1e6506e974c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X, y = datasets.load_diabetes(return_X_y=True) #load sklearn diabetes dataset for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "xbg_reg = xgb.XGBRegressor().fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75754e3-5ab1-4b05-9f5e-2a11b3996a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save as JSON file\n",
    "xbg_reg.save_model(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170aa4d-559d-4ab9-b410-b6903e67b795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Blank new instance to be loaded into\n",
    "import xgboost as xgb\n",
    "xgb_test = xgb.Booster()\n",
    "xgb_test.load_model(\"model.json\")\n",
    "\n",
    "\n",
    "#we can implement our health check locally that we will in our container later to verify\n",
    "health = xgb_test is not None\n",
    "status = 200 if health else 404\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dad474-cafb-47f0-b159-7eafd3922339",
   "metadata": {},
   "source": [
    "#### Create Test Dataset + Local inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8cece6-113e-4789-abf2-50e9a1772015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(X_test_scaled).to_csv(\"diabetes-test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed5d626-e7d7-4ca6-afe9-a3207a4081cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv(\"diabetes-test.csv\", header = None)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d08e63-2bb0-449f-9da6-52fbde80ae1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = xgb_test.predict(xgb.DMatrix(test))\n",
    "print(preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec27a31-eca5-4096-b0a4-5204ab509699",
   "metadata": {},
   "source": [
    "#### Test the predictor.py code for returning data format locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad9da7-cd8a-46f3-a6bf-eeb7946be958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "out = StringIO()\n",
    "pd.DataFrame({\"results\": preds}).to_csv(out, header=False, index=False)\n",
    "\n",
    "result = out.getvalue().rstrip(\n",
    "        \"\\n\"\n",
    "    )\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826df70-7466-4062-aac8-497592caf647",
   "metadata": {},
   "source": [
    "### Build ECR Image for XGBoost\n",
    "\n",
    "Container Structure\n",
    "\n",
    "- Dockerfile\n",
    "- XGB\n",
    "    - model.json (copy this local artifact to the container)\n",
    "    - nginx.conf (don't adjust)\n",
    "    - serve (don't adjust)\n",
    "    - wsgi.py (don't adjust)\n",
    "    - predictor.py (inference logic here, change as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f514e10-e650-42fa-b3be-32065b78e741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Name of algo -> ECR\n",
    "algorithm_name=sm-pretrained-xgboost\n",
    "\n",
    "cd container\n",
    "\n",
    "#make serve executable\n",
    "chmod +x XGB/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Region, defaults to us-west-2\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c129a3-fc57-4d06-be2e-56c1581482bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sm_client = boto3.client(service_name='sagemaker')\n",
    "runtime_sm_client = boto3.client(service_name='sagemaker-runtime')\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = boto3.session.Session().region_name\n",
    "#adjust the string with repository created in previous shell, this is the algo name you defined\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sm-pretrained-xgboost:latest'.format(account_id, region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3632c2-6245-422c-b95f-9adace5c66d4",
   "metadata": {},
   "source": [
    "### Upload Test Dataset for Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4484a9d0-27d6-4a42-92a6-ce8a62fe78e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "s3_test_path = f\"s3://{sess.default_bucket()}/\"+\"xgb-data-batch\"\n",
    "s3_test_uri = S3Uploader.upload(local_path=\"diabetes-test.csv\",desired_s3_uri=s3_test_path)\n",
    "print(f\"model artifcats uploaded to {s3_test_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1482c798-d8f8-4a40-9d37-d0d3d7ff2d77",
   "metadata": {},
   "source": [
    "### Create SM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646638e-2908-4f10-a8c2-084786815832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = 'xgb-model' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print('Model name: ' + model_name)\n",
    "\n",
    "container = {\n",
    "    'Image': image\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers = [container])\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f189254-85c6-452c-bb6d-f6a1aea4730c",
   "metadata": {},
   "source": [
    "### Batch Transform Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7335632-dd00-4df8-bbd8-cad0518605b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_output_path = f\"s3://{sess.default_bucket()}/\"+\"xgb-output-batch\"\n",
    "s3_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1695f9-5ef1-4ef9-a28a-f0c18b2d4cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_output={\n",
    "        'S3OutputPath': s3_output_path,\n",
    "    }\n",
    "\n",
    "\n",
    "data_input={\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': s3_test_uri\n",
    "            }\n",
    "        },\n",
    "        'ContentType': 'text/csv',\n",
    "        'SplitType': 'Line'\n",
    "    }\n",
    "\n",
    "hardware_resources={\n",
    "        'InstanceType': 'ml.m4.4xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e660048-95dd-4c98-acd1-f9396d6f739c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "transform_name = 'xgb-model-transform' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "response = sm_client.create_transform_job(TransformJobName = transform_name, ModelName = model_name, \n",
    "                                          TransformInput = data_input, TransformOutput = data_output,\n",
    "                                          TransformResources = hardware_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc54bf7-bb03-414c-9f09-b6b2a52c23c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wait for transform job to reach a terminal state (completed)\n",
    "import time\n",
    "\n",
    "describe_transform_response = sm_client.describe_transform_job(TransformJobName = transform_name)\n",
    "\n",
    "while describe_transform_response[\"TransformJobStatus\"] == \"InProgress\":\n",
    "    describe_transform_response = sm_client.describe_transform_job(TransformJobName = transform_name)\n",
    "    print(describe_transform_response[\"TransformJobStatus\"])\n",
    "    time.sleep(30)\n",
    "\n",
    "describe_transform_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e075f4e-142b-47f9-a7d3-57cf67a1f134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = describe_transform_response['TransformOutput']['S3OutputPath']\n",
    "results #capture your results in this S3 location"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
